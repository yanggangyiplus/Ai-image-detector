# AI 이미지 탐지 모델 비교 실험 보고서

## 📋 목차
1. [실험 개요](#실험-개요)
2. [실험 결과 요약](#실험-결과-요약)
3. [모델 성능 분석: 어떤 모델이 왜 좋은가](#모델-성능-분석-어떤-모델이-왜-좋은가)
4. [CNN vs ViT 구조적 차이](#cnn-vs-vit-구조적-차이)
5. [데이터셋 특성 vs 모델 적합성](#데이터셋-특성-vs-모델-적합성)
6. [오류 분석 (Misclassification 사례)](#오류-분석-misclassification-사례)
7. [향후 개선 방향](#향후-개선-방향)
8. [결론](#결론)

---

## 실험 개요

### 목적
AI 생성 이미지와 실제 이미지를 구분하는 이진 분류 태스크에서 CNN(ResNet18)과 Vision Transformer(ViT-Base) 모델의 성능을 비교하고, 각 모델의 장단점을 분석하여 최적의 모델을 선정합니다.

### 데이터셋
- **총 데이터**: 70,190개 이미지
  - Train: 49,132개 (Real: 42,099개, Fake: 7,033개)
  - Validation: 10,528개 (Real: 9,021개, Fake: 1,507개)
  - Test: 10,530개 (Real: 9,022개, Fake: 1,508개)
- **클래스 불균형**: Real:Fake 비율 약 6:1
- **이미지 크기**: 224×224로 전처리

### 실험 설정
| 항목 | CNN (ResNet18) | ViT (ViT-Base) |
|------|----------------|----------------|
| **모델 크기** | 11.7M 파라미터 | 86.7M 파라미터 |
| **배치 크기** | 32 | 16 |
| **학습률** | 1e-4 | 1e-5 |
| **에포크** | 16 (Early Stopping) | 15 (Early Stopping) |
| **Optimizer** | AdamW | AdamW |
| **Scheduler** | Cosine Annealing | ReduceLROnPlateau |
| **Best Epoch** | 6 | 5 |

---

## 실험 결과 요약

### 성능 지표 비교

| 지표 | CNN (ResNet18) | ViT (ViT-Base) | 차이 |
|------|----------------|----------------|------|
| **Test Accuracy** | 96.32% | **97.06%** | +0.74%p |
| **Test Precision** | 96.40% | **97.05%** | +0.65%p |
| **Test Recall** | 96.32% | **97.06%** | +0.74%p |
| **Test F1 Score** | 96.35% | **97.05%** | +0.70%p |
| **Best Val Accuracy** | 96.42% | **97.28%** | +0.86%p |
| **Best Val Loss** | 0.0919 | **0.0736** | -0.0183 |

### 클래스별 성능 분석

#### CNN (ResNet18)
- **Real 클래스**: Precision 98.18%, Recall 97.52%, F1 97.85%
- **AI 클래스**: Precision 85.72%, Recall 89.19%, F1 87.42%
- **Confusion Matrix**: 
  - Real → Real: 8,798개, Real → AI: 224개
  - AI → AI: 1,345개, AI → Real: 163개

#### ViT (ViT-Base)
- **Real 클래스**: Precision 98.25%, Recall 98.32%, F1 98.28%
- **AI 클래스**: Precision 89.88%, Recall 89.52%, F1 89.70%
- **Confusion Matrix**:
  - Real → Real: 8,870개, Real → AI: 152개
  - AI → AI: 1,350개, AI → Real: 158개

### 주요 발견사항
1. **ViT가 모든 지표에서 우수한 성능**을 보임 (약 0.7%p 향상)
2. **두 모델 모두 Real 클래스에서 높은 성능** (약 98%)
3. **AI 클래스 탐지에서 ViT가 더 우수** (F1: 87.42% → 89.70%)
4. **False Positive 감소**: Real을 AI로 오분류한 경우 ViT가 224개 → 152개로 감소

---

## 모델 성능 분석: 어떤 모델이 왜 좋은가

### ViT가 더 우수한 성능을 보인 이유

#### 1. **글로벌 컨텍스트 이해 능력**
- **ViT의 Self-Attention 메커니즘**: 이미지 전체의 패치 간 관계를 동시에 학습
- **CNN의 지역적 특성**: 컨볼루션 필터가 작은 지역적 패턴만 학습
- **AI 이미지 탐지에 유리한 이유**: AI 생성 이미지는 종종 전역적인 일관성 문제(예: 배경과 전경의 부자연스러운 경계, 조명의 불일치)를 가지고 있어, ViT의 글로벌 컨텍스트 이해가 더 효과적

#### 2. **더 빠른 수렴 속도**
- **ViT Best Epoch**: 5 epoch에서 최적 성능 달성
- **CNN Best Epoch**: 6 epoch에서 최적 성능 달성
- **학습 곡선 분석**: ViT는 초기부터 더 낮은 validation loss를 보이며 빠르게 수렴

#### 3. **더 나은 일반화 성능**
- **Validation-Test Gap**: ViT는 validation accuracy 97.28% → test accuracy 97.06%로 작은 차이 (0.22%p)
- **CNN**: validation accuracy 96.42% → test accuracy 96.32%로 비슷한 수준이지만 절대 성능이 낮음
- **Overfitting 저항**: ViT의 regularization 효과가 더 우수

#### 4. **AI 클래스 탐지 개선**
- **AI 클래스 F1 Score**: CNN 87.42% → ViT 89.70% (+2.28%p)
- **False Negative 감소**: AI 이미지를 Real로 오분류한 경우 163개 → 158개로 감소
- **False Positive 감소**: Real 이미지를 AI로 오분류한 경우 224개 → 152개로 감소 (32% 개선)

### CNN의 장점

#### 1. **효율적인 파라미터 사용**
- **모델 크기**: CNN 11.7M vs ViT 86.7M (약 7.4배 차이)
- **메모리 효율성**: 더 작은 모델로도 96% 이상의 성능 달성
- **추론 속도**: CNN이 더 빠른 추론 가능 (배치 크기 32 vs 16)

#### 2. **안정적인 학습**
- **학습 곡선**: CNN은 더 부드러운 수렴 곡선을 보임
- **하이퍼파라미터 민감도**: CNN이 상대적으로 덜 민감

---

## CNN vs ViT 구조적 차이

### 아키텍처 비교

#### CNN (ResNet18)
```
입력 이미지 (224×224×3)
    ↓
Convolutional Layers (지역적 특징 추출)
    ├─ Conv2D + BatchNorm + ReLU
    ├─ Residual Blocks (skip connections)
    └─ MaxPooling (다운샘플링)
    ↓
Global Average Pooling
    ↓
Fully Connected Layer (2 classes)
```

**특징**:
- **계층적 특징 학습**: 저수준 특징(엣지, 텍스처) → 고수준 특징(객체, 패턴)
- **지역적 수용 영역**: 각 컨볼루션 필터는 작은 지역만 관찰
- **인덕티브 바이어스**: 공간적 지역성과 번역 불변성 가정

#### ViT (Vision Transformer)
```
입력 이미지 (224×224×3)
    ↓
Patch Embedding (16×16 패치로 분할)
    ↓
Positional Encoding (위치 정보 추가)
    ↓
Transformer Encoder (12 layers)
    ├─ Multi-Head Self-Attention (글로벌 관계 학습)
    ├─ Feed-Forward Network
    └─ Layer Normalization
    ↓
[CLS] Token (전역 표현)
    ↓
Classification Head (2 classes)
```

**특징**:
- **글로벌 어텐션**: 모든 패치 간 관계를 동시에 학습
- **자기 지도 학습**: 사전 훈련된 가중치 활용
- **인덕티브 바이어스 없음**: 데이터로부터 모든 패턴 학습

### 학습 메커니즘 차이

| 측면 | CNN | ViT |
|------|-----|-----|
| **특징 추출** | 지역적 → 전역적 (계층적) | 전역적 (병렬) |
| **수용 영역** | 점진적 확장 | 즉시 전체 이미지 |
| **파라미터 수** | 11.7M | 86.7M |
| **학습 데이터 요구량** | 상대적으로 적음 | 많음 (사전 훈련 활용) |
| **계산 복잡도** | O(H×W×C) | O(N²×D) (N: 패치 수) |

### AI 이미지 탐지에 미치는 영향

#### CNN의 한계
1. **지역적 패턴에 집중**: 작은 지역의 이상 패턴을 놓칠 수 있음
2. **계층적 학습**: 고수준 특징에 도달하기 전까지 세부 패턴을 놓칠 수 있음
3. **수용 영역 제한**: 초기 레이어에서 작은 수용 영역으로 인한 전역적 일관성 파악 어려움

#### ViT의 장점
1. **전역적 일관성 검증**: Self-Attention으로 이미지 전체의 일관성 동시 검사
2. **세밀한 패턴 학습**: 모든 패치 간 관계를 학습하여 미세한 이상 패턴 탐지
3. **사전 훈련 활용**: 대규모 데이터셋으로 사전 훈련된 가중치로 일반화 성능 향상

---

## 데이터셋 특성 vs 모델 적합성

### 데이터셋 특성 분석

#### 1. **클래스 불균형**
- **Real:Fake 비율**: 약 6:1 (Real이 훨씬 많음)
- **영향**: 모델이 Real 클래스에 편향될 수 있음
- **대응**: 두 모델 모두 Weighted Loss 또는 Focal Loss 사용 가능

#### 2. **이미지 품질 다양성**
- **해상도**: 다양한 해상도의 이미지 포함
- **조명 조건**: 다양한 조명 환경
- **스타일**: 다양한 스타일의 이미지

#### 3. **AI 생성 이미지의 특징**
- **미세한 아티팩트**: 생성 과정에서 발생하는 작은 이상 패턴
- **전역적 일관성 문제**: 배경과 전경의 부자연스러운 경계
- **텍스처 패턴**: 반복적이거나 비정상적인 텍스처

### 모델별 적합성 분석 

#### CNN (ResNet18) 적합성
**✅ 장점**:
- **효율성**: 작은 모델 크기로 빠른 추론
- **안정성**: 검증된 아키텍처로 안정적인 학습
- **실용성**: 프로덕션 환경에서 배포 용이

**❌ 한계**:
- **지역적 패턴 집중**: 전역적 일관성 문제 탐지 어려움
- **클래스 불균형 영향**: AI 클래스 탐지 성능 상대적으로 낮음 (F1: 87.42%)

#### ViT (ViT-Base) 적합성
**✅ 장점**:
- **전역적 패턴 학습**: Self-Attention으로 이미지 전체의 일관성 검증
- **세밀한 패턴 탐지**: 모든 패치 간 관계 학습으로 미세한 아티팩트 탐지
- **클래스 불균형 대응**: AI 클래스 탐지 성능 우수 (F1: 89.70%)
- **일반화 성능**: 사전 훈련된 가중치로 더 나은 일반화

**❌ 한계**:
- **모델 크기**: 큰 모델 크기로 인한 메모리 및 계산 비용
- **학습 시간**: 더 많은 계산 리소스 필요

### 데이터셋-모델 매칭 분석

| 데이터셋 특성 | CNN 적합도 | ViT 적합도 | 우위 |
|--------------|-----------|-----------|------|
| **미세한 아티팩트 탐지** | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ViT |
| **전역적 일관성 검증** | ⭐⭐ | ⭐⭐⭐⭐⭐ | ViT |
| **클래스 불균형 대응** | ⭐⭐⭐ | ⭐⭐⭐⭐ | ViT |
| **계산 효율성** | ⭐⭐⭐⭐⭐ | ⭐⭐ | CNN |
| **실시간 추론** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | CNN |

**결론**: AI 이미지 탐지 태스크의 특성상 **전역적 일관성과 미세한 패턴 탐지가 중요**하므로, ViT가 더 적합한 아키텍처입니다.

---

## 오류 분석 (Misclassification 사례)

### 오분류 통계

#### CNN (ResNet18)
- **총 오분류**: 387개 (3.68%)
  - Real → AI (False Positive): 224개
  - AI → Real (False Negative): 163개

#### ViT (ViT-Base)
- **총 오분류**: 310개 (2.94%)
  - Real → AI (False Positive): 152개
  - AI → Real (False Negative): 158개

### 오분류 유형 분석

#### 1. **False Positive (Real → AI)**
**CNN**: 224개, **ViT**: 152개 (32% 감소)

**가능한 원인**:
- **저품질 이미지**: 압축 아티팩트나 노이즈가 많은 이미지
- **특이한 조명 조건**: 극단적인 조명이나 그림자
- **예술적 스타일**: 비현실적인 스타일의 실제 사진
- **전처리 아티팩트**: 이미지 전처리 과정에서 발생한 인위적 패턴

**ViT 개선 이유**:
- 전역적 컨텍스트를 고려하여 지역적 아티팩트에 덜 민감
- Self-Attention으로 이미지 전체의 자연스러움을 종합적으로 판단

#### 2. **False Negative (AI → Real)**
**CNN**: 163개, **ViT**: 158개 (3% 감소)

**가능한 원인**:
- **고품질 AI 이미지**: 최신 생성 모델로 만든 매우 사실적인 이미지
- **자연스러운 패턴**: AI 생성 이미지 중 자연스러운 패턴을 가진 경우
- **작은 아티팩트**: 탐지하기 어려운 미세한 생성 아티팩트

**개선 필요성**:
- 두 모델 모두 AI 클래스 탐지에서 개선 여지 존재
- 더 정교한 특징 추출 및 앙상블 방법 고려 필요

### 공통 오분류 패턴

두 모델이 모두 틀린 샘플은 **특히 어려운 케이스**로, 다음 특징을 가질 가능성이 높습니다:
1. **경계 케이스**: 실제와 AI 생성의 경계에 있는 이미지
2. **고품질 AI 이미지**: 최신 생성 모델의 산출물
3. **특이한 실제 이미지**: 비정상적인 조건의 실제 사진

---

## 향후 개선 방향

### 1. **데이터셋 개선**

#### 클래스 불균형 해결
- **데이터 증강**: AI 클래스에 대한 다양한 증강 기법 적용
  - MixUp, CutMix 등 고급 증강 기법
  - GAN 기반 합성 데이터 생성
- **샘플링 전략**: Balanced Sampling 또는 Focal Loss 적용

#### 데이터 품질 향상
- **고품질 AI 이미지 추가**: 최신 생성 모델(DALL-E 3, Midjourney v6 등)의 이미지 포함
- **다양성 확보**: 다양한 도메인, 스타일, 해상도의 이미지 수집
- **어노테이션 품질**: 전문가 검수를 통한 정확한 레이블링

### 2. **모델 아키텍처 개선**

#### 하이브리드 아키텍처
- **CNN-ViT 하이브리드**: EfficientNet-ViT 또는 ConvNeXt-ViT
- **다중 스케일 특징**: 다양한 해상도에서 특징 추출 후 융합

#### 고급 Transformer 모델
- **Swin Transformer**: 계층적 구조로 효율성과 성능 균형
- **DeiT (Data-efficient Image Transformer)**: 더 작은 데이터셋에 최적화
- **MAE (Masked Autoencoder)**: 자기 지도 학습으로 사전 훈련

### 3. **학습 전략 개선**

#### 손실 함수
- **Focal Loss**: 클래스 불균형 문제 해결
- **Label Smoothing**: 과적합 방지 및 일반화 성능 향상
- **Contrastive Loss**: 클래스 간 구분 명확화

#### 학습 기법
- **Knowledge Distillation**: 큰 모델의 지식을 작은 모델로 전이
- **Self-Training**: 모델이 생성한 고신뢰도 예측을 활용한 반복 학습
- **Meta-Learning**: 빠른 적응 능력 향상

### 4. **앙상블 및 후처리**

#### 모델 앙상블
- **다중 모델 앙상블**: CNN + ViT + 다른 아키텍처 조합
- **다양한 초기화**: 동일 아키텍처의 다양한 초기화 모델 앙상블
- **스태킹**: 메타 모델을 통한 예측 융합

#### 후처리 기법
- **임계값 조정**: 클래스별 최적 임계값 탐색
- **확률 보정**: Calibration을 통한 신뢰도 향상
- **불확실성 추정**: 모델의 예측 불확실성을 고려한 판단

### 5. **설명 가능성 및 해석성**

#### 시각화 기법
- **Attention Visualization**: ViT의 어텐션 맵 시각화
- **Grad-CAM**: CNN의 중요 영역 시각화
- **SHAP Values**: 특징 기여도 분석

#### 해석 가능한 특징
- **특징 분석**: 어떤 패턴이 AI 이미지를 구분하는지 분석
- **오류 패턴 분석**: 특정 유형의 오류에 대한 심층 분석

### 6. **실용적 개선**

#### 효율성 향상
- **모델 경량화**: Quantization, Pruning을 통한 모델 크기 감소
- **추론 최적화**: TensorRT, ONNX Runtime 등으로 추론 속도 향상
- **배치 처리**: 대량 이미지 처리 최적화

#### 프로덕션 고려사항
- **실시간 처리**: 지연 시간 최소화
- **확장성**: 대규모 트래픽 처리 능력
- **모니터링**: 모델 성능 지속적 모니터링 및 재학습 파이프라인

---

## 결론

### 주요 발견사항

1. **ViT 모델이 CNN보다 우수한 성능**을 보였습니다 (Test Accuracy: 96.32% → 97.06%)
2. **AI 이미지 탐지 태스크에 ViT가 더 적합**합니다:
   - 전역적 일관성 검증 능력
   - 미세한 아티팩트 탐지 능력
   - 클래스 불균형에 대한 더 나은 대응
3. **CNN의 실용적 가치**도 인정됩니다:
   - 효율적인 파라미터 사용
   - 빠른 추론 속도
   - 프로덕션 배포 용이성

### 권장사항

#### 단기 (즉시 적용 가능)
1. **ViT 모델을 메인 모델로 채택**: 최고 성능 달성
2. **클래스 불균형 해결**: Focal Loss 또는 데이터 증강 적용
3. **앙상블 고려**: CNN + ViT 앙상블로 성능 추가 향상

#### 중기 (3-6개월)
1. **하이브리드 아키텍처 탐색**: 효율성과 성능의 균형
2. **대규모 데이터셋 구축**: 더 다양한 AI 생성 이미지 수집
3. **설명 가능성 도입**: 모델의 판단 근거 시각화

#### 장기 (6개월 이상)
1. **자기 지도 학습**: 대규모 비지도 데이터로 사전 훈련
2. **도메인 적응**: 다양한 도메인에 대한 일반화 능력 향상
3. **실시간 시스템 구축**: 프로덕션 환경 최적화

### 최종 평가

이번 실험을 통해 **Vision Transformer가 AI 이미지 탐지 태스크에 더 적합한 아키텍처**임을 확인했습니다. 특히 전역적 컨텍스트 이해와 미세한 패턴 탐지 능력이 AI 생성 이미지의 특징을 더 잘 포착합니다. 다만, 실용적인 측면에서 CNN의 효율성도 고려하여, **용도에 따라 적절한 모델을 선택**하거나 **앙상블을 통해 두 모델의 장점을 결합**하는 것이 최선의 전략입니다.

---

## 참고 자료

- 실험 로그: `experiments/logs/`
- 체크포인트: `experiments/checkpoints/`
- 결과 시각화: `experiments/results/`
- 코드: `src/models/`, `src/training/`

---

**작성일**: 2025년 11월 18일  
**실험자**: AI Image Detector Team  
**버전**: 1.0

