"""
ì—¬ëŸ¬ ì´ë¯¸ì§€ í•œ ë²ˆì— ì¶”ë¡ í•˜ëŠ” ë°°ì¹˜ ì¶”ë¡  ì½”ë“œ 
"""
import torch
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from pathlib import Path
from tqdm import tqdm
import json
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))

try:
    from src.inference.inference import load_image
    from src.data.preprocess import get_test_transforms
except ImportError:
    from inference.inference import load_image
    from data.preprocess import get_test_transforms


class ImageInferenceDataset(Dataset):
    """
    ì¶”ë¡ ìš© ì´ë¯¸ì§€ ë°ì´í„°ì…‹
    
    Args:
        image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        transform: ì „ì²˜ë¦¬ ë³€í™˜ í•¨ìˆ˜
        image_size: ì´ë¯¸ì§€ í¬ê¸°
    """
    def __init__(self, image_paths, transform=None, image_size=224):
        self.image_paths = [Path(p) for p in image_paths]
        self.transform = transform
        self.image_size = image_size
        
        # ì¡´ìž¬í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í•„í„°ë§
        self.valid_paths = []
        self.invalid_paths = []
        for path in self.image_paths:
            if path.exists():
                self.valid_paths.append(path)
            else:
                self.invalid_paths.append(path)
        
        if self.invalid_paths:
            print(f"âš ï¸  {len(self.invalid_paths)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def __len__(self):
        return len(self.valid_paths)
    
    def __getitem__(self, idx):
        image_path = self.valid_paths[idx]
        try:
            image_tensor = load_image(image_path, self.transform, self.image_size)
            return image_tensor.squeeze(0), str(image_path)
        except Exception as e:
            raise RuntimeError(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}, ì˜¤ë¥˜: {e}")


def batch_predict(model, image_paths, device='cpu', batch_size=32, class_names=None, 
                  num_workers=0, show_progress=True):
    """
    ì—¬ëŸ¬ ì´ë¯¸ì§€ì— ëŒ€í•œ ë°°ì¹˜ ì˜ˆì¸¡ ìˆ˜í–‰
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸ (torch.nn.Module)
        image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
        device: ë””ë°”ì´ìŠ¤ ('cpu', 'cuda', 'mps')
        batch_size: ë°°ì¹˜ í¬ê¸°
        class_names: í´ëž˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['Real', 'AI'])
        num_workers: DataLoaderì˜ worker ìˆ˜ (macOSì—ì„œëŠ” 0 ê¶Œìž¥)
        show_progress: ì§„í–‰ ìƒí™© í‘œì‹œ ì—¬ë¶€
        
    Returns:
        results: ì˜ˆì¸¡ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ê° ê²°ê³¼ëŠ” ë”•ì…”ë„ˆë¦¬)
            - image_path: ì´ë¯¸ì§€ ê²½ë¡œ
            - predicted_class: ì˜ˆì¸¡ëœ í´ëž˜ìŠ¤ ì´ë¦„
            - predicted_class_idx: ì˜ˆì¸¡ëœ í´ëž˜ìŠ¤ ì¸ë±ìŠ¤
            - confidence: ì˜ˆì¸¡ ì‹ ë¢°ë„
            - probabilities: ëª¨ë“  í´ëž˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë”•ì…”ë„ˆë¦¬
            - is_ai: AI ì´ë¯¸ì§€ ì—¬ë¶€ (True/False)
    """
    model.eval()
    
    # ì´ë¯¸ì§€ ê²½ë¡œ ì²˜ë¦¬
    if isinstance(image_paths, (str, Path)):
        image_paths = Path(image_paths)
        if image_paths.is_dir():
            # ë””ë ‰í† ë¦¬ì¸ ê²½ìš° ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
            image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
            image_paths = [
                str(p) for p in image_paths.iterdir()
                if p.suffix.lower() in image_extensions
            ]
        else:
            image_paths = [str(image_paths)]
    
    if len(image_paths) == 0:
        raise ValueError("ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"ðŸ“Š ì´ {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œìž‘...")
    
    # í´ëž˜ìŠ¤ ì´ë¦„ ì²˜ë¦¬
    if class_names is None:
        class_names = [f'Class_{i}' for i in range(2)]  # ê¸°ë³¸ê°’: 2ê°œ í´ëž˜ìŠ¤
    
    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
    transform = get_test_transforms()
    dataset = ImageInferenceDataset(image_paths, transform=transform)
    
    if len(dataset) == 0:
        raise ValueError("ìœ íš¨í•œ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    dataloader = DataLoader(
        dataset, 
        batch_size=batch_size, 
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True if device != 'cpu' else False
    )
    
    all_results = []
    
    # ë°°ì¹˜ ì²˜ë¦¬
    iterator = tqdm(dataloader, desc="ë°°ì¹˜ ì¶”ë¡  ì¤‘") if show_progress else dataloader
    
    with torch.no_grad():
        for images, paths in iterator:
            images = images.to(device)
            
            outputs = model(images)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs.data, 1)
            
            # ê²°ê³¼ ì €ìž¥
            for i in range(len(paths)):
                pred_class_idx = predicted[i].item()
                pred_prob = probabilities[i][pred_class_idx].item()
                
                result = {
                    'image_path': paths[i],
                    'predicted_class': class_names[pred_class_idx],
                    'predicted_class_idx': pred_class_idx,
                    'confidence': float(pred_prob),
                    'probabilities': {
                        class_names[j]: float(probabilities[i][j].item())
                        for j in range(len(probabilities[i]))
                    },
                    'is_ai': pred_class_idx == 1 if len(class_names) == 2 else None
                }
                all_results.append(result)
    
    print(f"âœ… ì´ {len(all_results)}ê°œì˜ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ")
    
    return all_results


def save_batch_results(results, save_path, format='json'):
    """
    ë°°ì¹˜ ì¶”ë¡  ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ìž¥
    
    Args:
        results: batch_predictì˜ ë°˜í™˜ê°’
        save_path: ì €ìž¥í•  íŒŒì¼ ê²½ë¡œ
        format: ì €ìž¥ í˜•ì‹ ('json' ë˜ëŠ” 'csv')
    """
    save_path = Path(save_path)
    save_path.parent.mkdir(parents=True, exist_ok=True)
    
    if format.lower() == 'json':
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"âœ… JSON í˜•ì‹ìœ¼ë¡œ ì €ìž¥: {save_path}")
    
    elif format.lower() == 'csv':
        import pandas as pd
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        data = []
        for result in results:
            row = {
                'image_path': result['image_path'],
                'predicted_class': result['predicted_class'],
                'predicted_class_idx': result['predicted_class_idx'],
                'confidence': result['confidence'],
                'is_ai': result['is_ai']
            }
            # ê° í´ëž˜ìŠ¤ í™•ë¥  ì¶”ê°€
            for class_name, prob in result['probabilities'].items():
                row[f'prob_{class_name}'] = prob
            data.append(row)
        
        df = pd.DataFrame(data)
        df.to_csv(save_path, index=False, encoding='utf-8-sig')
        print(f"âœ… CSV í˜•ì‹ìœ¼ë¡œ ì €ìž¥: {save_path}")
    
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {format}")


def print_batch_summary(results, class_names=None):
    """
    ë°°ì¹˜ ì¶”ë¡  ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    
    Args:
        results: batch_predictì˜ ë°˜í™˜ê°’
        class_names: í´ëž˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    """
    if class_names is None:
        class_names = ['Real', 'AI']
    
    total = len(results)
    ai_count = sum(1 for r in results if r.get('is_ai', False))
    real_count = total - ai_count
    
    print("\n" + "=" * 60)
    print("ðŸ“Š ë°°ì¹˜ ì¶”ë¡  ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    print(f"ì´ ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {total}ê°œ")
    print(f"\ní´ëž˜ìŠ¤ë³„ ë¶„í¬:")
    print(f"  {class_names[0]}: {real_count}ê°œ ({real_count/total*100:.2f}%)")
    print(f"  {class_names[1]}: {ai_count}ê°œ ({ai_count/total*100:.2f}%)")
    
    if total > 0:
        avg_confidence = sum(r['confidence'] for r in results) / total
        print(f"\ní‰ê·  ì‹ ë¢°ë„: {avg_confidence:.4f} ({avg_confidence*100:.2f}%)")
        
        # ì‹ ë¢°ë„ ë¶„í¬
        high_conf = sum(1 for r in results if r['confidence'] >= 0.9)
        medium_conf = sum(1 for r in results if 0.7 <= r['confidence'] < 0.9)
        low_conf = sum(1 for r in results if r['confidence'] < 0.7)
        
        print(f"\nì‹ ë¢°ë„ ë¶„í¬:")
        print(f"  ë†’ìŒ (â‰¥90%): {high_conf}ê°œ ({high_conf/total*100:.2f}%)")
        print(f"  ì¤‘ê°„ (70-90%): {medium_conf}ê°œ ({medium_conf/total*100:.2f}%)")
        print(f"  ë‚®ìŒ (<70%): {low_conf}ê°œ ({low_conf/total*100:.2f}%)")
    
    print("=" * 60)

