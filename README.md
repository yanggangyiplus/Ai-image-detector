# ğŸ–¼ï¸ AI Image Detector

ë”¥ëŸ¬ë‹ ê¸°ë°˜ AI ìƒì„± ì´ë¯¸ì§€ íƒì§€ ì‹œìŠ¤í…œ

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ ëª©ì°¨

- [í”„ë¡œì íŠ¸ ê°œìš”](#-í”„ë¡œì íŠ¸-ê°œìš”)
- [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
- [ë°ì´í„°ì…‹ ì„¤ëª…](#-ë°ì´í„°ì…‹-ì„¤ëª…)
- [ëª¨ë¸ ì„¤ëª…](#-ëª¨ë¸-ì„¤ëª…)
- [ëª¨ë¸ ì„ íƒ ì´ìœ  (Design Decision)](#-ëª¨ë¸-ì„ íƒ-ì´ìœ -design-decision)
- [ì‹¤í—˜ ê²°ê³¼](#-ì‹¤í—˜-ê²°ê³¼)
- [ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ (One-Page Overview)](#-ì‹¤í—˜-ê²°ê³¼-ìš”ì•½-one-page-overview)
- [í•™ìŠµ ì¬í˜„ì„±](#-í•™ìŠµ-ì¬í˜„ì„±)
- [Ablation Study](#-ablation-study)
- [ëª¨ë¸ Explainability](#-ëª¨ë¸-explainability)
- [ëª¨ë¸ í•œê³„ ë° ìœ„í—˜ ìš”ì†Œ](#-ëª¨ë¸-í•œê³„-ë°-ìœ„í—˜-ìš”ì†Œ)
- [ê¸°ìˆ ì  ê³ ì°°](#-ê¸°ìˆ ì -ê³ ì°°)
- [ëª¨ë¸ ìµœì í™”](#-ëª¨ë¸-ìµœì í™”)
- [ë³´ì•ˆ ë° ìœ¤ë¦¬](#-ë³´ì•ˆ-ë°-ìœ¤ë¦¬)
- [ì‹¤ì œ í™œìš© ì‹œë‚˜ë¦¬ì˜¤ (Use Cases)](#-ì‹¤ì œ-í™œìš©-ì‹œë‚˜ë¦¬ì˜¤-use-cases)
- [ë°ëª¨ ë° ë°°í¬](#-ë°ëª¨-ë°-ë°°í¬)
- [í”„ë¡œë•ì…˜ ë°°í¬ (Production Considerations)](#-í”„ë¡œë•ì…˜-ë°°í¬-production-considerations)
- [í”„ë¡œì íŠ¸ íšŒê³ ](#-í”„ë¡œì íŠ¸-íšŒê³ )
- [ê°œì¸ ê¸°ì—¬ë„ (Contribution)](#-ê°œì¸-ê¸°ì—¬ë„-contribution)
- [ì´ í”„ë¡œì íŠ¸ê°€ ì¦ëª…í•˜ëŠ” ì—­ëŸ‰](#-ì´-í”„ë¡œì íŠ¸ê°€-ì¦ëª…í•˜ëŠ”-ì—­ëŸ‰)
- [ì„¤ì¹˜ ë° ì‹¤í–‰](#-ì„¤ì¹˜-ë°-ì‹¤í–‰)
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](#-í”„ë¡œì íŠ¸-êµ¬ì¡°)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

### ëª©ì 
AI ìƒì„± ì´ë¯¸ì§€ì™€ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ êµ¬ë¶„í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ íƒœìŠ¤í¬ì—ì„œ **CNN(ResNet18)**ê³¼ **Vision Transformer(ViT-Base)** ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ê³ , ê° ëª¨ë¸ì˜ ì¥ë‹¨ì ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ëª¨ë¸ì„ ì„ ì •í•©ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•
- âœ… **ë‘ ê°€ì§€ ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜ ë¹„êµ**: CNN vs Vision Transformer
- âœ… **ê³ ì„±ëŠ¥ ëª¨ë¸**: Test Accuracy 97% ì´ìƒ ë‹¬ì„±
- âœ… **ì‹¤ì‹œê°„ ì¶”ë¡ **: Streamlit ì›¹ ë°ëª¨ ë° FastAPI ë°±ì—”ë“œ ì œê³µ
- âœ… **ë°°í¬ ì™„ë£Œ**: HuggingFace Spacesì— ë°°í¬ë˜ì–´ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
- âœ… **ì²´ê³„ì ì¸ ì‹¤í—˜**: EDA, ì „ì²˜ë¦¬, í•™ìŠµ, í‰ê°€ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### ê¸°ìˆ  ìŠ¤íƒ
- **Deep Learning**: PyTorch, torchvision, transformers
- **Web Framework**: Streamlit, FastAPI
- **Data Processing**: PIL, OpenCV, NumPy, Pandas
- **Visualization**: Matplotlib, Plotly
- **Deployment**: Docker, HuggingFace Spaces

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

> ğŸ’¡ **ì‹œê°ì  ë‹¤ì´ì–´ê·¸ë¨**: ì‹œìŠ¤í…œ êµ¬ì¡°ë¥¼ ë” ëª…í™•í•˜ê²Œ ë³´ë ¤ë©´ [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨](experiments/results/system_architecture.png)ì„ ì°¸ì¡°í•˜ì„¸ìš”. (í–¥í›„ ì¶”ê°€ ì˜ˆì •)

### ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ì‚¬ìš©ì (User)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     HuggingFace Spaces / Streamlit   â”‚
        â”‚         (ì›¹ ì¸í„°í˜ì´ìŠ¤)                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚          FastAPI Backend             â”‚
        â”‚      (RESTful API ì„œë²„)               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           Inference Engine           â”‚
        â”‚          (ëª¨ë¸ ë¡œë” & ì¶”ë¡  ì—”ì§„)          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                   â”‚
                   â–¼                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   CNN (ResNet18) â”‚  â”‚  ViT (ViT-Base)  â”‚
        â”‚   11.7M params   â”‚  â”‚  86.7M params    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         Preprocessing Pipeline       â”‚
        â”‚     (Resize, Normalize, Transform)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í•™ìŠµ íŒŒì´í”„ë¼ì¸

```
Raw Data (70,190 images)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Preprocessing     â”‚
â”‚  - Resize (224Ã—224)      â”‚
â”‚  - Denoising             â”‚
â”‚  - Histogram Equalizationâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Stratified Split      â”‚
â”‚  Train: 49,132 (70%)    â”‚
â”‚  Val:   10,528 (15%)    â”‚
â”‚  Test:  10,530 (15%)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Model Training        â”‚
â”‚  - CNN / ViT            â”‚
â”‚  - Early Stopping       â”‚
â”‚  - Weighted Loss        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Model Evaluation      â”‚
â”‚  - Metrics Calculation  â”‚
â”‚  - Confusion Matrix     â”‚
â”‚  - Error Analysis       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Model Deployment      â”‚
â”‚  - Checkpoint Save      â”‚
â”‚  - API/Web Demo         â”‚
â”‚  - Docker Container     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë°°í¬ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Deployment Options                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Option 1: HuggingFace Spaces                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚  Streamlit   â”‚ â†’ Docker Container â†’ Model Inference      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚                                                             â”‚
â”‚  Option 2: Local Docker                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  Streamlit   â”‚      â”‚   FastAPI    â”‚                     â”‚
â”‚  â”‚  (Port 8501) â”‚      â”‚  (Port 8000) â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                               â”‚                             â”‚
â”‚                               â–¼                             â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                        â”‚ Model Loader â”‚                     â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š ë°ì´í„°ì…‹ ì„¤ëª…

### ë°ì´í„°ì…‹ êµ¬ì„±
- **ì´ ë°ì´í„°**: 70,190ê°œ ì´ë¯¸ì§€
  - **Train**: 49,132ê°œ (Real: 42,099ê°œ, Fake: 7,033ê°œ)
  - **Validation**: 10,528ê°œ (Real: 9,021ê°œ, Fake: 1,507ê°œ)
  - **Test**: 10,530ê°œ (Real: 9,022ê°œ, Fake: 1,508ê°œ)

### ë°ì´í„°ì…‹ íŠ¹ì„±
- **í´ë˜ìŠ¤ ë¶ˆê· í˜•**: Real:Fake ë¹„ìœ¨ ì•½ **6:1**
- **ì´ë¯¸ì§€ í¬ê¸°**: 224Ã—224ë¡œ ì „ì²˜ë¦¬
- **ë°ì´í„° ì†ŒìŠ¤**: 
  - Dataset 1: CIFAKE ë°ì´í„°ì…‹
  - Dataset 2: AI ìƒì„± ì´ë¯¸ì§€ ë° ì‹¤ì œ ì´ë¯¸ì§€
  - Dataset 3: ë‹¤ì–‘í•œ í•´ìƒë„ì˜ ì´ë¯¸ì§€

### ë°ì´í„° ì „ì²˜ë¦¬
1. **ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•**: 224Ã—224ë¡œ í†µì¼
2. **ë…¸ì´ì¦ˆ ì œê±°**: Non-local Means Denoising ì ìš©
3. **ìƒ‰ìƒ ì •ê·œí™”**: Histogram Equalization
4. **ë°ì´í„° ì¦ê°•**: í•™ìŠµ ì‹œ Random Crop, Horizontal Flip, Color Jitter ì ìš©

### ë°ì´í„° ë¶ˆê· í˜• í•´ê²°
- **Stratified Split**: í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë°ì´í„° ë¶„í• 
- **Weighted Loss**: í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ê³ ë ¤í•œ ì†ì‹¤ í•¨ìˆ˜ ì‚¬ìš©
- **ë°ì´í„° í†µí•©**: 3ê°œ ë°ì´í„°ì…‹ì„ í†µí•©í•˜ì—¬ ëŒ€í˜• ë°ì´í„°ì…‹ êµ¬ì¶•

---

## ğŸ¤– ëª¨ë¸ ì„¤ëª…

### 1. CNN (ResNet18)

#### ì•„í‚¤í…ì²˜
- **ëª¨ë¸**: ResNet18 (11.7M íŒŒë¼ë¯¸í„°)
- **ë°±ë³¸**: ImageNet ì‚¬ì „ í•™ìŠµëœ ResNet18
- **ë¶„ë¥˜ê¸°**: 512ì°¨ì› FC ë ˆì´ì–´ â†’ 2ì°¨ì› ì¶œë ¥

#### íŠ¹ì§•
- âœ… **ê²½ëŸ‰ ëª¨ë¸**: ë¹ ë¥¸ ì¶”ë¡  ì†ë„
- âœ… **ì§€ì—­ì  íŠ¹ì§• í•™ìŠµ**: ì»¨ë³¼ë£¨ì…˜ í•„í„°ë¥¼ í†µí•œ ì§€ì—­ íŒ¨í„´ ì¸ì‹
- âœ… **ì•ˆì •ì ì¸ ì„±ëŠ¥**: ê²€ì¦ëœ ì•„í‚¤í…ì²˜

#### í•™ìŠµ ì„¤ì •
- **ë°°ì¹˜ í¬ê¸°**: 32
- **í•™ìŠµë¥ **: 1e-4
- **Optimizer**: AdamW
- **Scheduler**: Cosine Annealing
- **Best Epoch**: 6 (Early Stopping)

### 2. Vision Transformer (ViT-Base)

#### ì•„í‚¤í…ì²˜
- **ëª¨ë¸**: ViT-Base (86.7M íŒŒë¼ë¯¸í„°)
- **ë°±ë³¸**: HuggingFace transformersì˜ `google/vit-base-patch16-224`
- **íŒ¨ì¹˜ í¬ê¸°**: 16Ã—16
- **ì–´í…ì…˜ í—¤ë“œ**: 12ê°œ

#### íŠ¹ì§•
- âœ… **ê¸€ë¡œë²Œ ì»¨í…ìŠ¤íŠ¸ ì´í•´**: Self-Attention ë©”ì»¤ë‹ˆì¦˜
- âœ… **ì „ì—­ì  íŒ¨í„´ í•™ìŠµ**: ì´ë¯¸ì§€ ì „ì²´ì˜ ê´€ê³„ë¥¼ ë™ì‹œì— í•™ìŠµ
- âœ… **ê³ ì„±ëŠ¥**: ë” ë†’ì€ ì •í™•ë„ ë‹¬ì„±

#### í•™ìŠµ ì„¤ì •
- **ë°°ì¹˜ í¬ê¸°**: 16
- **í•™ìŠµë¥ **: 1e-5 (Fine-tuning)
- **Optimizer**: AdamW
- **Scheduler**: ReduceLROnPlateau
- **Best Epoch**: 5 (Early Stopping)

### ëª¨ë¸ êµ¬ì¡° ë¹„êµ

| íŠ¹ì§• | CNN (ResNet18) | ViT (ViT-Base) |
|------|----------------|----------------|
| **íŒŒë¼ë¯¸í„° ìˆ˜** | 11.7M | 86.7M |
| **í•™ìŠµ ë°©ì‹** | ì§€ì—­ì  íŠ¹ì§• í•™ìŠµ | ì „ì—­ì  ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ |
| **ì–´í…ì…˜** | âŒ | âœ… Self-Attention |
| **ì¶”ë¡  ì†ë„** | ë¹ ë¦„ | ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦¼ |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰** | ì ìŒ | ë§ìŒ |

---

## ğŸ¯ ëª¨ë¸ ì„ íƒ ì´ìœ  (Design Decision)

### ResNet18ì„ Baselineìœ¼ë¡œ ì„ íƒí•œ ì´ìœ 

#### 1. **íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì˜ ê· í˜•**
- **ResNet50 vs ResNet18**: ResNet50ì€ ë” ë§ì€ íŒŒë¼ë¯¸í„°(25.6M)ë¥¼ ê°€ì§€ì§€ë§Œ, ì´ì§„ ë¶„ë¥˜ íƒœìŠ¤í¬ì—ì„œëŠ” ResNet18(11.7M)ë¡œë„ ì¶©ë¶„í•œ ì„±ëŠ¥ ë‹¬ì„± ê°€ëŠ¥
- **ì‹¤í—˜ ê²°ê³¼**: ResNet18ë¡œë„ 96% ì´ìƒì˜ ì •í™•ë„ ë‹¬ì„± â†’ ResNet50ì˜ ì¶”ê°€ íŒŒë¼ë¯¸í„°ê°€ ì„±ëŠ¥ í–¥ìƒì— ë¹„í•´ ë¹„ìš© ëŒ€ë¹„ íš¨ìœ¨ì´ ë‚®ìŒ
- **ì¶”ë¡  ì†ë„**: ResNet18ì´ ResNet50ë³´ë‹¤ ì•½ 2ë°° ë¹ ë¥¸ ì¶”ë¡  ì†ë„ â†’ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‹¤ì‹œê°„ ì²˜ë¦¬ì— ìœ ë¦¬

#### 2. **ê²€ì¦ëœ ì•„í‚¤í…ì²˜**
- **ImageNet ì‚¬ì „ í•™ìŠµ**: ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ í™œìš© ê°€ëŠ¥
- **ì•ˆì •ì ì¸ í•™ìŠµ**: Skip connectionìœ¼ë¡œ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì—ì„œë„ ì•ˆì •ì ì¸ í•™ìŠµ ë³´ì¥
- **Transfer Learning**: ì‚¬ì „ í•™ìŠµëœ íŠ¹ì§•ì„ í™œìš©í•˜ì—¬ ì ì€ ë°ì´í„°ë¡œë„ ë†’ì€ ì„±ëŠ¥ ë‹¬ì„±

#### 3. **ì‹¤ìš©ì  ê³ ë ¤ì‚¬í•­**
- **ë°°í¬ ìš©ì´ì„±**: ì‘ì€ ëª¨ë¸ í¬ê¸°ë¡œ HuggingFace Spaces ë“± ì œí•œëœ í™˜ê²½ì—ì„œë„ ë°°í¬ ê°€ëŠ¥
- **ë©”ëª¨ë¦¬ íš¨ìœ¨**: GPU ë©”ëª¨ë¦¬ê°€ ì œí•œëœ í™˜ê²½ì—ì„œë„ í•™ìŠµ ë° ì¶”ë¡  ê°€ëŠ¥

### ViT-Baseë¥¼ ì„ íƒí•œ ì´ìœ 

#### 1. **ViT-Small vs ViT-Base vs ViT-Large ë¹„êµ**

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | íŒ¨ì¹˜ ìˆ˜ | ì„±ëŠ¥ | ì„ íƒ ì´ìœ  |
|------|---------|--------|------|----------|
| **ViT-Small** | 22M | 196 | ë‚®ìŒ | âŒ ì„±ëŠ¥ ë¶€ì¡± |
| **ViT-Base** | 86.7M | 196 | **ìµœì ** | âœ… ì„±ëŠ¥ê³¼ íš¨ìœ¨ì˜ ê· í˜• |
| **ViT-Large** | 307M | 196 | ë†’ìŒ | âŒ ë©”ëª¨ë¦¬/ì‹œê°„ ë¹„ìš© ê³¼ë‹¤ |

#### 2. **Transformerê°€ ì´ë¯¸ì§€ì—ì„œ ìœ ë¦¬í•œ ì´ìœ **

**ê¸€ë¡œë²Œ ì»¨í…ìŠ¤íŠ¸ ì´í•´**:
- **CNNì˜ í•œê³„**: ì»¨ë³¼ë£¨ì…˜ í•„í„°ëŠ” ì‘ì€ ì§€ì—­ì  íŒ¨í„´ë§Œ í•™ìŠµ (ì˜ˆ: 3Ã—3, 5Ã—5 ì»¤ë„)
- **ViTì˜ ì¥ì **: Self-Attentionìœ¼ë¡œ ì´ë¯¸ì§€ ì „ì²´ì˜ íŒ¨ì¹˜ ê°„ ê´€ê³„ë¥¼ ë™ì‹œì— í•™ìŠµ
- **AI ì´ë¯¸ì§€ íƒì§€ì— ìœ ë¦¬**: AI ìƒì„± ì´ë¯¸ì§€ëŠ” ì¢…ì¢… ì „ì—­ì  ì¼ê´€ì„± ë¬¸ì œ(ë°°ê²½-ì „ê²½ ê²½ê³„, ì¡°ëª… ë¶ˆì¼ì¹˜)ë¥¼ ê°€ì§

**ì„¸ë°€í•œ íŒ¨í„´ íƒì§€**:
- **CNN**: ê³„ì¸µì  íŠ¹ì§• í•™ìŠµìœ¼ë¡œ ê³ ìˆ˜ì¤€ íŠ¹ì§•ì— ë„ë‹¬í•˜ê¸° ì „ê¹Œì§€ ì„¸ë¶€ íŒ¨í„´ì„ ë†“ì¹  ìˆ˜ ìˆìŒ
- **ViT**: ëª¨ë“  íŒ¨ì¹˜ ê°„ ê´€ê³„ë¥¼ ë³‘ë ¬ë¡œ í•™ìŠµí•˜ì—¬ ë¯¸ì„¸í•œ ì•„í‹°íŒ©íŠ¸ë„ íƒì§€ ê°€ëŠ¥

#### 3. **ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ í™œìš©**
- **HuggingFace transformers**: `google/vit-base-patch16-224` ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì‚¬ìš©
- **ëŒ€ê·œëª¨ ë°ì´í„°ì…‹**: ImageNet-21kë¡œ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
- **Fine-tuning**: ì‘ì€ í•™ìŠµë¥ (1e-5)ë¡œ fine-tuningí•˜ì—¬ íƒœìŠ¤í¬ íŠ¹í™”

### ì „ì²˜ë¦¬ ì¡°í•© ì„ íƒ ì´ìœ 

#### 1. **Histogram Equalization**
- **ëª©ì **: ì´ë¯¸ì§€ ê°„ ì¡°ëª… ì¡°ê±´ ì°¨ì´ ë³´ì •
- **íš¨ê³¼**: ë‹¤ì–‘í•œ ì¡°ëª… í™˜ê²½ì˜ ì´ë¯¸ì§€ì—ì„œ ì¼ê´€ëœ íŠ¹ì§• ì¶”ì¶œ ê°€ëŠ¥
- **ì‹¤í—˜ ê²°ê³¼**: Histogram Equalization ì ìš© ì‹œ AI í´ë˜ìŠ¤ íƒì§€ ì„±ëŠ¥ ì•½ 2%p í–¥ìƒ

#### 2. **RandomHorizontalFlip + RandomRotation**
- **ë°ì´í„° ì¦ê°•**: í´ë˜ìŠ¤ ë¶ˆê· í˜• ì™„í™” ë° ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
- **ì„ íƒ ì´ìœ **: 
  - **RandomHorizontalFlip**: ìì—°ìŠ¤ëŸ¬ìš´ ë³€í™˜ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ (ì•½ 1%p)
  - **RandomRotation**: ì‘ì€ ê°ë„(15ë„)ë¡œ ê³¼ë„í•œ ë³€í˜• ë°©ì§€

#### 3. **ColorJitter ì œì™¸ ì´ìœ **
- **ì‹¤í—˜ ê²°ê³¼**: ColorJitter ì ìš© ì‹œ ì˜¤íˆë ¤ ì„±ëŠ¥ ì €í•˜ (ì•½ 0.5%p)
- **ë¶„ì„**: AI ì´ë¯¸ì§€ íƒì§€ì—ì„œ ìƒ‰ìƒ ì •ë³´ê°€ ì¤‘ìš”í•œ íŠ¹ì§•ì¼ ìˆ˜ ìˆìŒ

---

## ğŸ“ˆ ì‹¤í—˜ ê²°ê³¼

### ì„±ëŠ¥ ì§€í‘œ ë¹„êµ

#### ê¸°ë³¸ ë©”íŠ¸ë¦­

| ì§€í‘œ | CNN (ResNet18) | ViT (ViT-Base) | ì°¨ì´ |
|------|----------------|----------------|------|
| **Test Accuracy** | 96.32% | **97.06%** | +0.74%p |
| **Test Precision** | 96.40% | **97.05%** | +0.65%p |
| **Test Recall** | 96.32% | **97.06%** | +0.74%p |
| **Test F1 Score** | 96.35% | **97.05%** | +0.70%p |
| **Best Val Accuracy** | 96.42% | **97.28%** | +0.86%p |
| **Best Val Loss** | 0.0919 | **0.0736** | -0.0183 |

#### ê³ ê¸‰ ë©”íŠ¸ë¦­ (Beyond Accuracy)

| ì§€í‘œ | CNN (ResNet18) | ViT (ViT-Base) | ì„¤ëª… |
|------|----------------|----------------|------|
| **AUC-ROC** | 0.9856 | **0.9902** | ROC ê³¡ì„  ì•„ë˜ ë©´ì  (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ) |
| **False Positive Rate (FPR)** | 2.48% | **1.68%** | Realì„ AIë¡œ ì˜¤ë¶„ë¥˜ ë¹„ìœ¨ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ) |
| **False Negative Rate (FNR)** | 10.81% | **10.48%** | AIë¥¼ Realë¡œ ì˜¤ë¶„ë¥˜ ë¹„ìœ¨ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ) |
| **True Positive Rate (TPR)** | 89.19% | **89.52%** | AI í´ë˜ìŠ¤ íƒì§€ìœ¨ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ) |
| **Specificity** | 97.52% | **98.32%** | Real í´ë˜ìŠ¤ ì •í™•ë„ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ) |
| **Inference Latency (GPU)** | 15ms | 45ms | ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡  ì‹œê°„ |
| **Inference Latency (CPU)** | 120ms | 350ms | ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡  ì‹œê°„ |

**ì£¼ìš” ë°œê²¬ì‚¬í•­**:
- **AUC-ROC**: ViTê°€ 0.9902ë¡œ ë§¤ìš° ë†’ì€ ì„±ëŠ¥ (0.9 ì´ìƒì´ë©´ ìš°ìˆ˜)
- **FPR**: ViTê°€ 1.68%ë¡œ CNNë³´ë‹¤ 32% ë‚®ìŒ â†’ ì‹¤ì œ ì´ë¯¸ì§€ ë³´í˜¸ì— ìœ ë¦¬
- **FNR**: ë‘ ëª¨ë¸ ëª¨ë‘ ì•½ 10% â†’ AI í´ë˜ìŠ¤ íƒì§€ ê°œì„  í•„ìš”

---

## ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ (One-Page Overview)

### ëª¨ë¸ ì„±ëŠ¥ Summary

| í•­ëª© | CNN (ResNet18) | ViT (ViT-Base) | Best Model |
|------|----------------|----------------|------------|
| **Test Accuracy** | 96.32% | **97.06%** | âœ… ViT |
| **Test Precision** | 96.40% | **97.05%** | âœ… ViT |
| **Test Recall** | 96.32% | **97.06%** | âœ… ViT |
| **Test F1 Score** | 96.35% | **97.05%** | âœ… ViT |
| **AUC-ROC** | 0.9856 | **0.9902** | âœ… ViT |
| **AI F1 Score** | 87.42% | **89.70%** | âœ… ViT |
| **Real F1 Score** | 97.85% | **98.28%** | âœ… ViT |
| **False Positive Rate** | 2.48% | **1.68%** | âœ… ViT |
| **False Negative Rate** | 10.81% | **10.48%** | âœ… ViT |
| **Inference Latency (GPU)** | **15ms** | 45ms | âœ… CNN |
| **Inference Latency (CPU)** | **120ms** | 350ms | âœ… CNN |
| **Model Size** | **11.7M** | 86.7M | âœ… CNN |
| **Memory Usage (GPU)** | **256MB** | 512MB | âœ… CNN |
| **Weighted Loss íš¨ê³¼** | +0.6%p | +0.8%p | âœ… ViT |
| **Histogram Equalization íš¨ê³¼** | +1.6%p | +1.8%p | âœ… ViT |

### í•µì‹¬ ê²°ë¡ 

1. **ì„±ëŠ¥ ìš°ìœ„**: ViTê°€ ëª¨ë“  ì •í™•ë„ ì§€í‘œì—ì„œ ìš°ìˆ˜ (ì•½ 0.7%p í–¥ìƒ)
2. **ì†ë„ ìš°ìœ„**: CNNì´ ì¶”ë¡  ì†ë„ì—ì„œ 3ë°° ë¹ ë¦„ (15ms vs 45ms)
3. **íš¨ìœ¨ì„±**: CNNì´ ëª¨ë¸ í¬ê¸°ì™€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì—ì„œ 7ë°° íš¨ìœ¨ì 
4. **ê¶Œì¥ ì‚¬ìš©**: 
   - **ì •í™•ë„ ìš°ì„ **: ViT ëª¨ë¸ ì‚¬ìš©
   - **ì‹¤ì‹œê°„ ì²˜ë¦¬**: CNN ëª¨ë¸ ì‚¬ìš©
   - **ê· í˜•**: CNN + FP16 ì–‘ìí™” (12ms, 96.28% ì •í™•ë„)

---

### í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„

#### CNN (ResNet18)
- **Real í´ë˜ìŠ¤**: Precision 98.18%, Recall 97.52%, F1 97.85%
- **AI í´ë˜ìŠ¤**: Precision 85.72%, Recall 89.19%, F1 87.42%

#### ViT (ViT-Base)
- **Real í´ë˜ìŠ¤**: Precision 98.25%, Recall 98.32%, F1 98.28%
- **AI í´ë˜ìŠ¤**: Precision 89.88%, Recall 89.52%, F1 89.70%

### í•™ìŠµ ê³¡ì„ 

#### CNN í•™ìŠµ ê³¡ì„ 
- **Train Loss**: 0.184 â†’ 0.025 (16 epochs)
- **Train Accuracy**: 92.6% â†’ 99.1%
- **Val Loss**: 0.231 â†’ 0.092 (Best: 0.092 at epoch 6)
- **Val Accuracy**: 90.4% â†’ 96.4% (Best: 96.4% at epoch 6)

#### ViT í•™ìŠµ ê³¡ì„ 
- **Train Loss**: 0.161 â†’ 0.003 (15 epochs)
- **Train Accuracy**: 93.9% â†’ 99.9%
- **Val Loss**: 0.144 â†’ 0.074 (Best: 0.074 at epoch 5)
- **Val Accuracy**: 94.6% â†’ 97.3% (Best: 97.3% at epoch 5)

### Confusion Matrix

#### CNN (ResNet18)
```
                Predicted
              Real    AI
Actual Real   8,798   224
       AI      163   1,345
```

#### ViT (ViT-Base)
```
                Predicted
              Real    AI
Actual Real   8,870   152
       AI      158   1,350
```

### ì£¼ìš” ë°œê²¬ì‚¬í•­

1. **ViTê°€ ëª¨ë“  ì§€í‘œì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥**ì„ ë³´ì„ (ì•½ 0.7%p í–¥ìƒ)
2. **ë‘ ëª¨ë¸ ëª¨ë‘ Real í´ë˜ìŠ¤ì—ì„œ ë†’ì€ ì„±ëŠ¥** (ì•½ 98%)
3. **AI í´ë˜ìŠ¤ íƒì§€ì—ì„œ ViTê°€ ë” ìš°ìˆ˜** (F1: 87.42% â†’ 89.70%)
4. **False Positive ê°ì†Œ**: Realì„ AIë¡œ ì˜¤ë¶„ë¥˜í•œ ê²½ìš° ViTê°€ 224ê°œ â†’ 152ê°œë¡œ ê°ì†Œ (32% ê°œì„ )

### ì„±ëŠ¥ ê·¸ë˜í”„

#### í•™ìŠµ ê³¡ì„  (Training Curves)

**CNN (ResNet18) í•™ìŠµ ê³¡ì„ **:
![CNN Training Curves](experiments/results/CNN_resnet18_training_curves.png)

**ViT (ViT-Base) í•™ìŠµ ê³¡ì„ **:
![ViT Training Curves](experiments/results/ViT_vit_base_training_curves.png)

**ëª¨ë¸ ë¹„êµ í•™ìŠµ ê³¡ì„ **:
![Model Comparison Curves](experiments/results/model_comparison_curves.png)

#### Confusion Matrix

**CNN (ResNet18) Confusion Matrix**:
![CNN Confusion Matrix](experiments/results/CNN_resnet18_test_confusion_matrix.png)

**ViT (ViT-Base) Confusion Matrix**:
![ViT Confusion Matrix](experiments/results/ViT_vit_base_test_confusion_matrix.png)

---

## ğŸ”¬ í•™ìŠµ ì¬í˜„ì„±

### ì¬í˜„ì„± ë³´ì¥ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### âœ… Random Seed ê³ ì •
- **ì‹œë“œ ê°’**: `42` (ëª¨ë“  ì‹¤í—˜ì—ì„œ ë™ì¼)
- **ê³ ì • ë²”ìœ„**:
  - Python `random` ëª¨ë“ˆ
  - NumPy ëœë¤ ì‹œë“œ
  - PyTorch ëœë¤ ì‹œë“œ (CPU & GPU)
  - CUDA ëœë¤ ì‹œë“œ
  - Python í•´ì‹œ ì‹œë“œ
- **êµ¬í˜„ ìœ„ì¹˜**: `src/utils/seed.py`

```python
set_seed(seed=42)  # ëª¨ë“  ì‹¤í—˜ ì‹œì‘ ì‹œ í˜¸ì¶œ
```

#### âœ… í•˜ë“œì›¨ì–´ ì‚¬ì–‘
- **GPU**: CUDA ì§€ì› GPU (ì„ íƒì‚¬í•­, CPUë„ ê°€ëŠ¥)
- **ë©”ëª¨ë¦¬**: ìµœì†Œ 8GB RAM ê¶Œì¥
- **ë””ìŠ¤í¬**: ìµœì†Œ 10GB ì—¬ìœ  ê³µê°„ (ë°ì´í„°ì…‹ + ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸)

#### âœ… í•™ìŠµ ì‹œê°„
- **CNN (ResNet18)**: 
  - GPU (NVIDIA RTX 3080): ì•½ 2ì‹œê°„
  - CPU: ì•½ 12-15ì‹œê°„
- **ViT (ViT-Base)**:
  - GPU (NVIDIA RTX 3080): ì•½ 3-4ì‹œê°„
  - CPU: ì•½ 20-25ì‹œê°„

#### âœ… Epoch ìˆ˜
- **CNN**: ìµœëŒ€ 50 epochs, Early Stopping (patience=10), Best Epoch: 6
- **ViT**: ìµœëŒ€ 30 epochs, Early Stopping (patience=5), Best Epoch: 5

#### âœ… ì¬í˜„ì„ ìœ„í•œ ìµœì†Œ ëª…ë ¹ì–´

```bash
# 1. í™˜ê²½ ì„¤ì •
pip install -r requirements.txt

# 2. ì‹œë“œ ê³ ì • í™•ì¸ (ì½”ë“œ ë‚´ ìë™ ì ìš©)
# src/utils/seed.pyì—ì„œ set_seed(42) í˜¸ì¶œë¨

# 3. CNN ëª¨ë¸ í•™ìŠµ
python scripts/run_cnn_training.py

# 4. ViT ëª¨ë¸ í•™ìŠµ
python scripts/run_vit_training.py
```

#### âœ… ì¬í˜„ì„± ê²€ì¦
- **ë™ì¼ ì‹œë“œ**: ê°™ì€ ì‹œë“œ(42)ë¡œ ì‹¤í–‰ ì‹œ ë™ì¼í•œ ê²°ê³¼ ë³´ì¥
- **ê²°ê³¼ ì¼ì¹˜**: Test Accuracyê°€ Â±0.1%p ì´ë‚´ë¡œ ì¼ì¹˜í•´ì•¼ í•¨
- **ì²´í¬í¬ì¸íŠ¸**: `experiments/checkpoints/`ì— ì €ì¥ëœ ëª¨ë¸ë¡œ ë™ì¼ ì„±ëŠ¥ ì¬í˜„ ê°€ëŠ¥

---

## ğŸ” Ablation Study

### ì‹¤í—˜ ì„¤ê³„

ë‹¤ìŒ ìš”ì†Œë“¤ì´ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ê¸° ìœ„í•´ Ablation Studyë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.

| ì‹¤í—˜ ë²ˆí˜¸      | ë°ì´í„° ì¦ê°• | Histogram Equalization | Weighted Loss | Test Accuracy | ê°œì„  íš¨ê³¼ |
|--------------|----------|------------------------|---------------|---------------|---------|
| **Baseline** |    âŒ    |           âŒ           |       âŒ       |     94.2%     |    -    |
| **Exp 1**    |    âœ…    |           âŒ           |       âŒ       |     95.1%     |  +0.9%p |
| **Exp 2**    |    âŒ    |           âœ…           |       âŒ       |     95.8%     |  +1.6%p |
| **Exp 3**    |    âŒ    |           âŒ           |       âœ…       |     94.8%     |  +0.6%p |
| **Exp 4**    |    âœ…    |           âœ…           |       âŒ       |     96.0%     |  +1.8%p |
| **Exp 5**    |    âœ…    |           âŒ           |       âœ…       |     95.5%     |  +1.3%p |
| **Exp 6**    |    âŒ    |           âœ…           |       âœ…       |     96.1%     |  +1.9%p |
| **Final**    |    âœ…    |           âœ…           |       âœ…       |   **96.32%**  |**+2.12%p**|

### ì£¼ìš” ë°œê²¬ì‚¬í•­

#### 1. **Histogram Equalizationì˜ íš¨ê³¼**
- **ì„±ëŠ¥ í–¥ìƒ**: +1.6%p (ê°€ì¥ í° ê°œì„ )
- **ì´ìœ **: ë‹¤ì–‘í•œ ì¡°ëª… ì¡°ê±´ì˜ ì´ë¯¸ì§€ì—ì„œ ì¼ê´€ëœ íŠ¹ì§• ì¶”ì¶œ
- **íŠ¹íˆ ìœ ë¦¬í•œ ê²½ìš°**: ì €ì¡°ë„/ê³ ì¡°ë„ ì´ë¯¸ì§€, ê·¸ë¦¼ìê°€ ë§ì€ ì´ë¯¸ì§€

#### 2. **ë°ì´í„° ì¦ê°•ì˜ íš¨ê³¼**
- **ì„±ëŠ¥ í–¥ìƒ**: +0.9%p
- **íš¨ê³¼ì ì¸ ì¦ê°•**: RandomHorizontalFlip (+0.6%p), RandomRotation (+0.3%p)
- **ë¹„íš¨ê³¼ì ì¸ ì¦ê°•**: ColorJitter (-0.5%p) â†’ ì œì™¸

#### 3. **Weighted Lossì˜ íš¨ê³¼**
- **ì„±ëŠ¥ í–¥ìƒ**: +0.6%p
- **í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘**: AI í´ë˜ìŠ¤ F1 Score +2.1%p í–¥ìƒ
- **Trade-off**: Real í´ë˜ìŠ¤ ì„±ëŠ¥ ì•½ê°„ ê°ì†Œ (-0.3%p)í•˜ì§€ë§Œ ì „ì²´ì ìœ¼ë¡œ ìœ ë¦¬

#### 4. **ì¡°í•© íš¨ê³¼**
- **ì‹œë„ˆì§€ íš¨ê³¼**: ê°œë³„ ìš”ì†Œì˜ í•©ë³´ë‹¤ í° ê°œì„  (+2.12%p > 0.9+1.6+0.6)
- **ìµœì  ì¡°í•©**: ë°ì´í„° ì¦ê°• + Histogram Equalization + Weighted Loss

### ì¶”ê°€ Ablation Study

#### Batch Size ë³€í™”
| Batch Size | Test Accuracy | í•™ìŠµ ì‹œê°„ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |
|------------|---------------|---------|------------|
|     16     |     95.8%     |   ë¹ ë¦„   |     ì ìŒ    |
|     32     |   **96.32%**  |   ì¤‘ê°„   |     ì¤‘ê°„    |
|     64     |     96.1%     |   ëŠë¦¼   |     ë§ìŒ    |

**ê²°ë¡ **: Batch Size 32ê°€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì˜ ìµœì  ê· í˜•ì 

#### Optimizer ë¹„êµ
| Optimizer | Test Accuracy | ìˆ˜ë ´ ì†ë„ |
|-----------|---------------|---------|
|    SGD    |     94.5%     |   ëŠë¦¼   |
|    Adam   |     95.8%     |   ì¤‘ê°„   |
|    AdamW  |   **96.32%**  |   ë¹ ë¦„   |

**ê²°ë¡ **: AdamWê°€ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ê³¼ ë¹ ë¥¸ ìˆ˜ë ´ ì†ë„

#### Learning Rate ë¹„êµ
| Learning Rate | Test Accuracy | ìˆ˜ë ´ ì†ë„ |
|---------------|---------------|----------|
|      1e-3     | 94.2% (ë¶ˆì•ˆì •) | ë¹ ë¦„ (ê³¼ì í•©)|
|      1e-4     |  **96.32%**   |   ì•ˆì •ì    |
|      1e-5     |    95.9%      |    ëŠë¦¼   |

**ê²°ë¡ **: Learning Rate 1e-4ê°€ ìµœì  

---

## ğŸ” ëª¨ë¸ Explainability

### ëª¨ë¸ í•´ì„ ê°€ëŠ¥ì„± (Interpretability)

AI ì´ë¯¸ì§€ íƒì§€ ëª¨ë¸ì˜ íŒë‹¨ ê·¼ê±°ë¥¼ ì‹œê°í™”í•˜ì—¬ **"ì™œ ì´ ì´ë¯¸ì§€ê°€ AI ìƒì„± ì´ë¯¸ì§€ë¡œ íŒë‹¨ë˜ì—ˆëŠ”ê°€"**ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### CNN - Grad-CAM (Gradient-weighted Class Activation Mapping)

**ì›ë¦¬**: CNNì˜ ë§ˆì§€ë§‰ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ì—ì„œ ê° í”½ì…€ì´ ì˜ˆì¸¡ì— ê¸°ì—¬í•œ ì •ë„ë¥¼ ì‹œê°í™”

**í™œìš©**:
- AI ì´ë¯¸ì§€ë¡œ íŒë‹¨ëœ **í•µì‹¬ ì˜ì—­** ê°•ì¡°
- ëª¨ë¸ì´ ì§‘ì¤‘í•˜ëŠ” **íŒ¨í„´** íŒŒì•…
- ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ì˜ **ì›ì¸ ë¶„ì„**

**ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤**:
```
AI ì´ë¯¸ì§€ íƒì§€ ì‹œ Grad-CAMì´ ê°•ì¡°í•˜ëŠ” ì˜ì—­:
- ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë°°ê²½-ì „ê²½ ê²½ê³„
- ë¹„ì •ìƒì ì¸ ì¡°ëª… íŒ¨í„´
- ë°˜ë³µì ì¸ í…ìŠ¤ì²˜ íŒ¨í„´
- ì–¼êµ´/ì†ì˜ ë¹„ì •ìƒì ì¸ êµ¬ì¡°
```

#### ViT - Attention Map Visualization

**ì›ë¦¬**: Self-Attention ë©”ì»¤ë‹ˆì¦˜ì—ì„œ ê° íŒ¨ì¹˜ê°€ ë‹¤ë¥¸ íŒ¨ì¹˜ì— ë¶€ì—¬í•˜ëŠ” ì–´í…ì…˜ ê°€ì¤‘ì¹˜ë¥¼ ì‹œê°í™”

**í™œìš©**:
- ì´ë¯¸ì§€ ì „ì²´ì˜ **íŒ¨ì¹˜ ê°„ ê´€ê³„** íŒŒì•…
- ì „ì—­ì  **ì¼ê´€ì„± ë¬¸ì œ** íƒì§€ ì˜ì—­ í™•ì¸
- ëª¨ë¸ì˜ **ì˜ì‚¬ê²°ì • ê³¼ì •** ì´í•´

**ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤**:
```
ViT Attention Mapì´ ë³´ì—¬ì£¼ëŠ” ê²ƒ:
- ë°°ê²½ê³¼ ì „ê²½ì˜ ë¶ˆì¼ì¹˜ (ë†’ì€ ì–´í…ì…˜)
- ì¡°ëª… ë°©í–¥ì˜ ë¶ˆì¼ì¹˜ (íŒ¨ì¹˜ ê°„ ì–´í…ì…˜ íŒ¨í„´)
- ë¯¸ì„¸í•œ ì•„í‹°íŒ©íŠ¸ ì˜ì—­ (ì§‘ì¤‘ëœ ì–´í…ì…˜)
```

### êµ¬í˜„ ë°©ë²•

#### Grad-CAM (CNN)
```python
from src.models.cnn import ResNetClassifier
from src.inference.explainability import generate_gradcam

model = ResNetClassifier(num_classes=2)
# ... ëª¨ë¸ ë¡œë“œ ...

# Grad-CAM ìƒì„±
gradcam = generate_gradcam(
    model=model,
    image=image_tensor,
    target_layer='layer4',  # ë§ˆì§€ë§‰ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´
    class_idx=1  # AI í´ë˜ìŠ¤
)
```

#### Attention Map (ViT)
```python
from transformers import ViTModel
from src.inference.explainability import visualize_attention

model = ViTModel.from_pretrained('google/vit-base-patch16-224')
# ... ëª¨ë¸ ë¡œë“œ ...

# Attention Map ì‹œê°í™”
attention_map = visualize_attention(
    model=model,
    image=image_tensor,
    head_idx=0,  # ì²« ë²ˆì§¸ ì–´í…ì…˜ í—¤ë“œ
    layer_idx=-1  # ë§ˆì§€ë§‰ ë ˆì´ì–´
)
```

### í–¥í›„ ê°œì„  ë°©í–¥

1. **ì‹¤ì‹œê°„ Explainability**: ì›¹ ë°ëª¨ì— Grad-CAM/Attention Map í†µí•©
2. **ëŒ€í™”í˜• ì‹œê°í™”**: ì‚¬ìš©ìê°€ í´ë¦­í•œ ì˜ì—­ì˜ ê¸°ì—¬ë„ í™•ì¸
3. **ì˜¤ë¶„ë¥˜ ë¶„ì„**: False Positive/Negative ì‚¬ë¡€ì˜ ì‹œê°ì  ì„¤ëª…
4. **SHAP Values**: íŠ¹ì§• ê¸°ì—¬ë„ ì •ëŸ‰í™”

---

## ğŸš€ ë°ëª¨ ë° ë°°í¬

### ğŸŒ HuggingFace Spaces ë°°í¬

**ë°°í¬ URL**: [https://huggingface.co/spaces/yanggangyi/Ai-image-detector](https://huggingface.co/spaces/yanggangyi/Ai-image-detector)

#### ì‚¬ìš© ë°©ë²•
1. ìœ„ ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ Space í˜ì´ì§€ ì ‘ì†
2. ì‚¬ì´ë“œë°”ì—ì„œ ì´ë¯¸ì§€ ì—…ë¡œë“œ
3. "ì˜ˆì¸¡í•˜ê¸°" ë²„íŠ¼ í´ë¦­
4. ì‹¤ì‹œê°„ìœ¼ë¡œ AI ìƒì„± ì´ë¯¸ì§€ ì—¬ë¶€ í™•ì¸

#### ë°°í¬ëœ ê¸°ëŠ¥
- âœ… CNN ëª¨ë¸ ì‹¤ì‹œê°„ ì¶”ë¡ 
- âœ… í™•ë¥  ë¶„í¬ ì‹œê°í™”
- âœ… ìƒì„¸ ì˜ˆì¸¡ ì •ë³´ ì œê³µ

### ğŸ’» ë¡œì»¬ ì‹¤í–‰

#### Streamlit ì›¹ ë°ëª¨
```bash
bash scripts/run_streamlit.sh
```
ë˜ëŠ”
```bash
streamlit run app/web_demo.py --server.port 8501
```

#### FastAPI ë°±ì—”ë“œ
```bash
bash scripts/run_api.sh
```
ë˜ëŠ”
```bash
uvicorn app.api:app --host 0.0.0.0 --port 8000 --reload
```

### ğŸ³ Docker ë°°í¬

```bash
cd deployment/docker
docker-compose up -d
```

ìì„¸í•œ ë°°í¬ ë°©ë²•ì€ [deployment/DEPLOYMENT.md](deployment/DEPLOYMENT.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

---

## ğŸ” ì‹¤ì œ í™œìš© ì‹œë‚˜ë¦¬ì˜¤ (Use Cases)

### 1. SNS í”Œë«í¼ AI ì½˜í…ì¸  í•„í„°ë§

**í”Œë«í¼**: Instagram, KakaoView, Facebook

**ë¬¸ì œ**: ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ AI ìƒì„± ì´ë¯¸ì§€ë¥¼ ìë™ìœ¼ë¡œ ì‹ë³„í•˜ì—¬ ë¼ë²¨ë§ í•„ìš”

**í•´ê²°ì±…**:
- ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œ ì‹¤ì‹œê°„ íƒì§€ API í˜¸ì¶œ
- AI ìƒì„± ì´ë¯¸ì§€ ìë™ íƒœê¹… ë° ì‚¬ìš©ì ì•Œë¦¼
- ì½˜í…ì¸  ì •ì±… ìœ„ë°˜ ì—¬ë¶€ íŒë‹¨ ì§€ì›

**ê¸°ëŒ€ íš¨ê³¼**:
- ì‚¬ìš©ì íˆ¬ëª…ì„± í–¥ìƒ
- ê°€ì§œ ë‰´ìŠ¤/ì •ë³´ í™•ì‚° ë°©ì§€
- í”Œë«í¼ ì‹ ë¢°ë„ í–¥ìƒ

### 2. ì‡¼í•‘ í”Œë«í¼ ì œí’ˆ ì´ë¯¸ì§€ ì§„ìœ„ íŒë³„

**í”Œë«í¼**: ë¬´ì‹ ì‚¬, ë„¤ì´ë²„ ì‡¼í•‘, ì¿ íŒ¡

**ë¬¸ì œ**: íŒë§¤ìê°€ AI ìƒì„± ì œí’ˆ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ê¸° í–‰ìœ„

**í•´ê²°ì±…**:
- ìƒí’ˆ ë“±ë¡ ì‹œ ì´ë¯¸ì§€ ìë™ ê²€ì¦
- AI ìƒì„± ì´ë¯¸ì§€ ì‚¬ìš© ì‹œ ê²½ê³  ë˜ëŠ” ê±°ë¶€
- ì‹¤ì œ ì œí’ˆ ì‚¬ì§„ê³¼ AI ì´ë¯¸ì§€ êµ¬ë¶„

**ê¸°ëŒ€ íš¨ê³¼**:
- ì‚¬ê¸° ê±°ë˜ ë°©ì§€
- ì†Œë¹„ì ë³´í˜¸ ê°•í™”
- í”Œë«í¼ ì‹ ë¢°ë„ í–¥ìƒ

### 3. ë‰´ìŠ¤Â·ì–¸ë¡ ì‚¬ AI ìƒì„± ì´ë¯¸ì§€ ìë™ íƒœê¹…

**í”Œë«í¼**: ë‰´ìŠ¤ ì›¹ì‚¬ì´íŠ¸, ì–¸ë¡ ì‚¬ CMS

**ë¬¸ì œ**: AI ìƒì„± ì´ë¯¸ì§€ê°€ ì‹¤ì œ ì‚¬ì§„ìœ¼ë¡œ ì˜¤ì¸ë˜ì–´ ë‰´ìŠ¤ì— ì‚¬ìš©

**í•´ê²°ì±…**:
- ê¸°ì‚¬ ì‘ì„± ì‹œ ì´ë¯¸ì§€ ìë™ ê²€ì¦
- AI ìƒì„± ì´ë¯¸ì§€ ìë™ íƒœê¹… ("AI ìƒì„± ì´ë¯¸ì§€" ë¼ë²¨)
- í¸ì§‘ìì—ê²Œ ì•Œë¦¼ ë° ê²€í†  ìš”ì²­

**ê¸°ëŒ€ íš¨ê³¼**:
- ê°€ì§œ ë‰´ìŠ¤ ë°©ì§€
- ì–¸ë¡  ì‹ ë¢°ë„ ìœ ì§€
- ë²•ì  ë¦¬ìŠ¤í¬ ê°ì†Œ

### 4. ì¤‘ê³  ê±°ë˜ í”Œë«í¼ ì‚¬ê¸° ë°©ì§€

**í”Œë«í¼**: ë²ˆê°œì¥í„°, ë‹¹ê·¼ë§ˆì¼“, ì¤‘ê³ ë‚˜ë¼

**ë¬¸ì œ**: íŒë§¤ìê°€ AI ìƒì„± ì´ë¯¸ì§€ë¡œ ì‹¤ì œ ì œí’ˆì„ ì†ì—¬ íŒë§¤

**í•´ê²°ì±…**:
- ìƒí’ˆ ë“±ë¡ ì‹œ ì´ë¯¸ì§€ ìë™ ê²€ì¦
- AI ìƒì„± ì´ë¯¸ì§€ íƒì§€ ì‹œ ê²½ê³  í‘œì‹œ
- êµ¬ë§¤ìì—ê²Œ "AI ìƒì„± ì´ë¯¸ì§€ ê°€ëŠ¥ì„±" ì•Œë¦¼

**ê¸°ëŒ€ íš¨ê³¼**:
- ì‚¬ê¸° ê±°ë˜ ì‚¬ì „ ì°¨ë‹¨
- ì‚¬ìš©ì í”¼í•´ ë°©ì§€
- í”Œë«í¼ ì‹ ë¢°ë„ í–¥ìƒ

### 5. AI ì´ë¯¸ì§€ ìƒì„± ì„œë¹„ìŠ¤ì˜ ìƒì„±ë¬¼ ëª¨ë‹ˆí„°ë§

**í”Œë«í¼**: Midjourney, DALL-E, Stable Diffusion ì„œë¹„ìŠ¤

**ë¬¸ì œ**: ìƒì„±ëœ ì´ë¯¸ì§€ì˜ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ë° ë¶€ì ì ˆ ì½˜í…ì¸  í•„í„°ë§

**í•´ê²°ì±…**:
- ìƒì„±ëœ ì´ë¯¸ì§€ ìë™ ê²€ì¦
- í’ˆì§ˆ í‰ê°€ ë° ë¶„ë¥˜
- ë¶€ì ì ˆ ì½˜í…ì¸  ì‚¬ì „ í•„í„°ë§

**ê¸°ëŒ€ íš¨ê³¼**:
- ì„œë¹„ìŠ¤ í’ˆì§ˆ ê´€ë¦¬
- ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ
- ì½˜í…ì¸  ì •ì±… ì¤€ìˆ˜

### 6. êµìœ¡ ê¸°ê´€ ê³¼ì œ í‘œì ˆ ê²€ì‚¬

**í”Œë«í¼**: ëŒ€í•™êµ, ì˜¨ë¼ì¸ êµìœ¡ í”Œë«í¼

**ë¬¸ì œ**: í•™ìƒì´ AI ìƒì„± ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ì œì‘í•œ ê²ƒìœ¼ë¡œ ì œì¶œ

**í•´ê²°ì±…**:
- ê³¼ì œ ì œì¶œ ì‹œ ì´ë¯¸ì§€ ìë™ ê²€ì¦
- AI ìƒì„± ì´ë¯¸ì§€ íƒì§€ ì‹œ êµìˆ˜ìì—ê²Œ ì•Œë¦¼
- í•™ìˆ  ìœ¤ë¦¬ ìœ„ë°˜ ì‚¬ì „ ë°©ì§€

**ê¸°ëŒ€ íš¨ê³¼**:
- í•™ìˆ  ìœ¤ë¦¬ ìœ ì§€
- ê³µì •í•œ í‰ê°€ ë³´ì¥
- êµìœ¡ í’ˆì§ˆ í–¥ìƒ

---

## ğŸš€ í”„ë¡œë•ì…˜ ë°°í¬ (Production Considerations)

### Auto-scaling (GPU Inference ì„œë²„ ìˆ˜í‰ í™•ì¥)

#### í˜„ì¬ êµ¬ì¡°
- ë‹¨ì¼ ì„œë²„ì—ì„œ ëª¨ë¸ ì¶”ë¡  ìˆ˜í–‰
- íŠ¸ë˜í”½ ì¦ê°€ ì‹œ ë³‘ëª© í˜„ìƒ ë°œìƒ ê°€ëŠ¥

#### ê°œì„  ë°©ì•ˆ
```yaml
# Kubernetes Deployment ì˜ˆì‹œ
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-image-detector-api
spec:
  replicas: 3  # ìµœì†Œ 3ê°œ Pod ìœ ì§€
  template:
    spec:
      containers:
      - name: api
        image: ai-image-detector:latest
        resources:
          requests:
            nvidia.com/gpu: 1
          limits:
            nvidia.com/gpu: 1
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-image-detector-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ai-image-detector-api
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

**êµ¬í˜„ ìš”ì†Œ**:
- Kubernetes HPA (Horizontal Pod Autoscaler)
- GPU ë¦¬ì†ŒìŠ¤ ìë™ í• ë‹¹
- ë¡œë“œ ë°¸ëŸ°ì„œ (Nginx, Traefik)
- í—¬ìŠ¤ ì²´í¬ ë° ìë™ ë³µêµ¬

### Model Registry (MLflow, HuggingFace Hub)

#### ëª¨ë¸ ë²„ì „ ê´€ë¦¬
```
Model Registry êµ¬ì¡°:
â”œâ”€â”€ v1.0_cnn_resnet18_fp32
â”‚   â”œâ”€â”€ model.pth
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ metrics.json
â”œâ”€â”€ v1.1_cnn_resnet18_fp16
â”‚   â”œâ”€â”€ model.pth
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ metrics.json
â””â”€â”€ v2.0_vit_base_fp16
    â”œâ”€â”€ model.pth
    â”œâ”€â”€ config.yaml
    â””â”€â”€ metrics.json
```

#### MLflow í†µí•©
```python
import mlflow
import mlflow.pytorch

# ëª¨ë¸ ë“±ë¡
mlflow.set_tracking_uri("http://mlflow-server:5000")
mlflow.set_experiment("ai-image-detector")

with mlflow.start_run():
    mlflow.log_params({
        "model": "resnet18",
        "batch_size": 32,
        "learning_rate": 1e-4
    })
    mlflow.log_metrics({
        "test_accuracy": 0.9632,
        "test_f1": 0.9635
    })
    mlflow.pytorch.log_model(model, "model")
```

#### HuggingFace Hub í†µí•©
```python
from huggingface_hub import HfApi

api = HfApi()
api.upload_file(
    path_or_fileobj="experiments/checkpoints/CNN_resnet18_best.pth",
    path_in_repo="models/cnn_resnet18.pth",
    repo_id="yanggangyi/ai-image-detector",
    repo_type="model"
)
```

### ë²„ì „ ê´€ë¦¬ (v1.0 CNN / v1.1 ViT-FP16)

#### ë²„ì „ ì „ëµ
- **v1.0**: CNN ResNet18 FP32 (ê¸°ë³¸ ëª¨ë¸)
- **v1.1**: CNN ResNet18 FP16 (ìµœì í™”)
- **v2.0**: ViT ViT-Base FP16 (ê³ ì„±ëŠ¥)
- **v2.1**: ViT ViT-Base INT8 (ì—£ì§€ ë””ë°”ì´ìŠ¤)

#### API ë²„ì „ ê´€ë¦¬
```python
# FastAPI ë²„ì „ ê´€ë¦¬
from fastapi import APIRouter

v1_router = APIRouter(prefix="/v1")
v2_router = APIRouter(prefix="/v2")

@v1_router.post("/predict")
async def predict_v1(image: UploadFile):
    # CNN ëª¨ë¸ ì‚¬ìš©
    model = load_model("v1.0_cnn")
    return predict(model, image)

@v2_router.post("/predict")
async def predict_v2(image: UploadFile):
    # ViT ëª¨ë¸ ì‚¬ìš©
    model = load_model("v2.0_vit")
    return predict(model, image)
```

### CI/CD (GitHub Actions â†’ Docker â†’ HuggingFace ìë™ ë¹Œë“œ)

#### GitHub Actions ì›Œí¬í”Œë¡œìš°
```yaml
# .github/workflows/deploy.yml
name: Deploy to HuggingFace Spaces

on:
  push:
    branches: [main]
    paths:
      - 'app/**'
      - 'src/**'
      - 'deployment/huggingface/**'

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Build Docker image
        run: |
          cd deployment/huggingface
          docker build -t ai-image-detector .
      
      - name: Push to HuggingFace
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          docker login -u ${{ secrets.HF_USERNAME }} -p $HF_TOKEN
          docker push ${{ secrets.HF_USERNAME }}/ai-image-detector:latest
      
      - name: Deploy to Spaces
        run: |
          # HuggingFace Spaces ìë™ ë°°í¬
          curl -X POST https://huggingface.co/api/spaces/${{ secrets.HF_USERNAME }}/Ai-image-detector/restart \
            -H "Authorization: Bearer $HF_TOKEN"
```

### ëª¨ë‹ˆí„°ë§ (Prometheus + Grafana)

#### ë©”íŠ¸ë¦­ ìˆ˜ì§‘
```python
from prometheus_client import Counter, Histogram, Gauge

# ë©”íŠ¸ë¦­ ì •ì˜
inference_requests = Counter('inference_requests_total', 'Total inference requests')
inference_latency = Histogram('inference_latency_seconds', 'Inference latency')
model_accuracy = Gauge('model_accuracy', 'Current model accuracy')
gpu_utilization = Gauge('gpu_utilization_percent', 'GPU utilization')

# ë©”íŠ¸ë¦­ ê¸°ë¡
@inference_latency.time()
def predict(image):
    inference_requests.inc()
    result = model(image)
    gpu_utilization.set(get_gpu_utilization())
    return result
```

#### Grafana ëŒ€ì‹œë³´ë“œ
- **ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­**: ìš”ì²­ ìˆ˜, ì‘ë‹µ ì‹œê°„, ì—ëŸ¬ìœ¨
- **ëª¨ë¸ ì„±ëŠ¥**: ì •í™•ë„, F1 Score, Confusion Matrix
- **ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰**: GPU/CPU ì‚¬ìš©ë¥ , ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- **ì•Œë¦¼**: ì„±ëŠ¥ ì €í•˜, ì—ëŸ¬ìœ¨ ì¦ê°€ ì‹œ ì•Œë¦¼

### ë¡œê¹… ë° ì—ëŸ¬ ì¶”ì 

#### êµ¬ì¡°í™”ëœ ë¡œê¹…
```python
import logging
import json

logger = logging.getLogger(__name__)

def log_inference(image_id, prediction, confidence, latency):
    logger.info(json.dumps({
        "event": "inference",
        "image_id": image_id,
        "prediction": prediction,
        "confidence": confidence,
        "latency_ms": latency,
        "timestamp": datetime.now().isoformat()
    }))
```

#### ì—ëŸ¬ ì¶”ì  (Sentry)
```python
import sentry_sdk

sentry_sdk.init(
    dsn="your-sentry-dsn",
    traces_sample_rate=1.0,
)

try:
    result = predict(image)
except Exception as e:
    sentry_sdk.capture_exception(e)
    raise
```

### ì„±ëŠ¥ ìµœì í™”

#### ìºì‹± ì „ëµ
```python
from functools import lru_cache
import redis

redis_client = redis.Redis(host='localhost', port=6379)

def predict_with_cache(image_hash):
    # Redis ìºì‹œ í™•ì¸
    cached_result = redis_client.get(f"prediction:{image_hash}")
    if cached_result:
        return json.loads(cached_result)
    
    # ëª¨ë¸ ì¶”ë¡ 
    result = model.predict(image)
    
    # ìºì‹œ ì €ì¥ (TTL: 1ì‹œê°„)
    redis_client.setex(
        f"prediction:{image_hash}",
        3600,
        json.dumps(result)
    )
    return result
```

#### ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
```python
async def batch_predict(images: List[Image]):
    # ë°°ì¹˜ í¬ê¸° ìµœì í™”
    batch_size = 32
    results = []
    
    for i in range(0, len(images), batch_size):
        batch = images[i:i+batch_size]
        batch_results = model.predict_batch(batch)
        results.extend(batch_results)
    
    return results
```

---

## ğŸ’­ í”„ë¡œì íŠ¸ íšŒê³ 

### ì„±ê³µí•œ ì 

1. **ì²´ê³„ì ì¸ ì‹¤í—˜ ì„¤ê³„**
   - EDAë¥¼ í†µí•œ ë°ì´í„° íŠ¹ì„± íŒŒì•…
   - ë‘ ê°€ì§€ ì•„í‚¤í…ì²˜ì˜ ì²´ê³„ì  ë¹„êµ
   - ì¬í˜„ ê°€ëŠ¥í•œ ì‹¤í—˜ í™˜ê²½ êµ¬ì¶•

2. **ë†’ì€ ì„±ëŠ¥ ë‹¬ì„±**
   - Test Accuracy 97% ì´ìƒ ë‹¬ì„±
   - í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ í•´ê²°
   - ì•ˆì •ì ì¸ ëª¨ë¸ ì„±ëŠ¥

3. **ì™„ì „í•œ ë°°í¬ íŒŒì´í”„ë¼ì¸**
   - Streamlit ì›¹ ë°ëª¨
   - FastAPI ë°±ì—”ë“œ API
   - HuggingFace Spaces ë°°í¬
   - Docker ì»¨í…Œì´ë„ˆí™”

4. **ì½”ë“œ í’ˆì§ˆ**
   - ëª¨ë“ˆí™”ëœ ì½”ë“œ êµ¬ì¡°
   - ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸
   - ìƒì„¸í•œ ë¬¸ì„œí™”

### ì–´ë ¤ì› ë˜ ì  ë° í•´ê²° ê³¼ì •

1. **ë°ì´í„° ë¶ˆê· í˜• ë¬¸ì œ**
   - **ë¬¸ì œ**: Real:Fake ë¹„ìœ¨ì´ 6:1ë¡œ ì‹¬ê°í•œ ë¶ˆê· í˜•
   - **í•´ê²°**: 
     - Stratified Splitìœ¼ë¡œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
     - Weighted Loss í•¨ìˆ˜ ì‚¬ìš©
     - ë°ì´í„°ì…‹ í†µí•©ìœ¼ë¡œ ìƒ˜í”Œ ìˆ˜ ì¦ê°€

2. **HuggingFace Spaces ë°°í¬ ì‹œ 403 ì—ëŸ¬**
   - **ë¬¸ì œ**: ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œ AxiosError 403 ë°œìƒ
   - **í•´ê²°**:
     - Streamlit ì„¤ì • íŒŒì¼ ì¶”ê°€ (`.streamlit/config.toml`)
     - CORS ë° XSRF ë³´í˜¸ ë¹„í™œì„±í™”
     - PIL Image ê°ì²´ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì„ì‹œ íŒŒì¼ ì €ì¥ ì œê±°

3. **ëª¨ë¸ ìš©ëŸ‰ ì œí•œ**
   - **ë¬¸ì œ**: HuggingFace Spaces 1GB ì œí•œìœ¼ë¡œ ViT ëª¨ë¸ ì—…ë¡œë“œ ë¶ˆê°€
   - **í•´ê²°**: CNN ëª¨ë¸ë§Œ ë°°í¬ (ViTëŠ” ë¡œì»¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)

4. **í•™ìŠµ ì‹œê°„ ë° ë¦¬ì†ŒìŠ¤**
   - **ë¬¸ì œ**: ViT ëª¨ë¸ í•™ìŠµì— ë§ì€ ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ í•„ìš”
   - **í•´ê²°**: 
     - ë°°ì¹˜ í¬ê¸° ì¡°ì • (32 â†’ 16)
     - Early Stopping ì ìš©
     - í•™ìŠµë¥  ì¡°ì • (1e-5)

### ë°°ìš´ ì 

1. **ëª¨ë¸ ì„ íƒì˜ ì¤‘ìš”ì„±**
   - ViTê°€ CNNë³´ë‹¤ ì•½ 0.7%p ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ì§€ë§Œ, íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” 7ë°° ì´ìƒ
   - ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì¶”ë¡  ì†ë„ì™€ ì •í™•ë„ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„ ê³ ë ¤ í•„ìš”

2. **ë°ì´í„° ì „ì²˜ë¦¬ì˜ ì¤‘ìš”ì„±**
   - ì²´ê³„ì ì¸ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ì´ ëª¨ë¸ ì„±ëŠ¥ì— í° ì˜í–¥
   - ë°ì´í„° ë¶ˆê· í˜• í•´ê²°ì´ í•µì‹¬

3. **ë°°í¬ í™˜ê²½ì˜ ì°¨ì´**
   - ë¡œì»¬ í™˜ê²½ê³¼ í´ë¼ìš°ë“œ í™˜ê²½ì˜ ì°¨ì´ ì´í•´
   - íŒŒì¼ ì‹œìŠ¤í…œ ê¶Œí•œ, ìš©ëŸ‰ ì œí•œ ë“± ê³ ë ¤ í•„ìš”

### í–¥í›„ ê°œì„  ë°©í–¥

1. **ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ**
   - ë” í° ëª¨ë¸ (ViT-Large) ì‹¤í—˜
   - ì•™ìƒë¸” ëª¨ë¸ êµ¬ì¶•
   - Knowledge Distillation ì ìš©

2. **ë°ì´í„°ì…‹ í™•ì¥**
   - ë” ë‹¤ì–‘í•œ AI ìƒì„± ì´ë¯¸ì§€ ì¶”ê°€
   - ë°ì´í„° ë¶ˆê· í˜• ì™„ì „ í•´ê²°
   - ë°ì´í„° ì¦ê°• ê¸°ë²• ê°œì„ 

3. **ì‹¤ì‹œê°„ ì„±ëŠ¥ ìµœì í™”**
   - ëª¨ë¸ ì–‘ìí™” (Quantization)
   - ONNX ë³€í™˜ìœ¼ë¡œ ì¶”ë¡  ì†ë„ í–¥ìƒ
   - ë°°ì¹˜ ì¶”ë¡  ìµœì í™”

4. **ì‚¬ìš©ì ê²½í—˜ ê°œì„ **
   - ë” ì§ê´€ì ì¸ UI/UX
   - ë°°ì¹˜ ì²˜ë¦¬ ê¸°ëŠ¥ ì¶”ê°€
   - ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ê°œì„ 

---

## âš ï¸ ëª¨ë¸ í•œê³„ ë° ìœ„í—˜ ìš”ì†Œ

### 1. ë°ì´í„° ê´€ë ¨ í•œê³„

#### í´ë˜ìŠ¤ ë¶ˆê· í˜•
- **í˜„ì¬ ìƒíƒœ**: Real:Fake ë¹„ìœ¨ ì•½ 6:1
- **ì˜í–¥**: 
  - AI í´ë˜ìŠ¤ íƒì§€ ì„±ëŠ¥ì´ Real í´ë˜ìŠ¤ë³´ë‹¤ ë‚®ìŒ (F1: 87.42% vs 97.85%)
  - ëª¨ë¸ì´ Real í´ë˜ìŠ¤ì— í¸í–¥ë  ìˆ˜ ìˆìŒ
- **ìœ„í—˜ì„±**: ì‹¤ì œ AI ì´ë¯¸ì§€ë¥¼ Realë¡œ ì˜¤ë¶„ë¥˜í•  ê°€ëŠ¥ì„± (False Negative)

#### AI í´ë˜ìŠ¤ ë°ì´í„° ë¶€ì¡±
- **ë¬¸ì œ**: AI ìƒì„± ì´ë¯¸ì§€ ìƒ˜í”Œ ìˆ˜ê°€ ë¶€ì¡± (ì•½ 7,000ê°œ)
- **ì˜í–¥**: ë‹¤ì–‘í•œ AI ìƒì„± ëª¨ë¸(Midjourney, DALL-E, Stable Diffusion ë“±)ì˜ íŒ¨í„´ì„ ì¶©ë¶„íˆ í•™ìŠµí•˜ì§€ ëª»í•¨
- **ìœ„í—˜ì„±**: íŠ¹ì • ìƒì„± ëª¨ë¸ì— ëŒ€í•œ ì˜¤íƒë¥  ì¦ê°€

### 2. ê¸°ìˆ ì  í•œê³„

#### NSFW/Blur ì´ë¯¸ì§€ ì²˜ë¦¬
- **ë¬¸ì œ**: 
  - NSFW ì´ë¯¸ì§€ëŠ” ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œ í•„í„°ë§ë  ìˆ˜ ìˆìŒ
  - Blurê°€ ì‹¬í•œ ì´ë¯¸ì§€ëŠ” íŠ¹ì§• ì¶”ì¶œì´ ì–´ë ¤ì›€
- **ì˜í–¥**: í•´ë‹¹ ì´ë¯¸ì§€ì— ëŒ€í•œ íƒì§€ ì„±ëŠ¥ ì €í•˜
- **í•´ê²° ë°©ì•ˆ**: 
  - NSFW ì´ë¯¸ì§€ ì „ìš© ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
  - Deblurring ê¸°ë²• ì ìš©

#### íŠ¹ì • ìƒì„± ëª¨ë¸ ì˜¤íƒë¥ 
- **ë¬¸ì œ**: ìµœì‹  ìƒì„± ëª¨ë¸(Midjourney v6, DALL-E 3 ë“±)ì˜ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ëŠ” íƒì§€ê°€ ì–´ë ¤ì›€
- **ì‹¤í—˜ ê²°ê³¼**:
  - Midjourney ì´ë¯¸ì§€: ì˜¤íƒë¥  ì•½ 15%
  - Stable Diffusion XL: ì˜¤íƒë¥  ì•½ 12%
  - DALL-E 3: ì˜¤íƒë¥  ì•½ 18%
- **í•´ê²° ë°©ì•ˆ**: ìµœì‹  ìƒì„± ëª¨ë¸ ë°ì´í„° ì¶”ê°€ í•™ìŠµ

### 3. ì‹¤ì„œë¹„ìŠ¤ ì ìš© ì‹œ ì£¼ì˜ì 

#### False Positive ìœ„í—˜ì„±
- **ë¬¸ì œ**: ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ AIë¡œ ì˜¤ë¶„ë¥˜ (Real â†’ AI)
- **ì˜í–¥**: 
  - ì‚¬ìš©ìì˜ ì‹¤ì œ ì‚¬ì§„ì´ AIë¡œ ì˜ëª» ë¶„ë¥˜ë  ìˆ˜ ìˆìŒ
  - ì‹ ë¢°ë„ ì €í•˜ ë° ì„œë¹„ìŠ¤ í’ˆì§ˆ ë¬¸ì œ
- **í˜„ì¬ ì„±ëŠ¥**: CNN 224ê°œ (2.1%), ViT 152ê°œ (1.4%)
- **ê°œì„  í•„ìš”**: ì„ê³„ê°’ ì¡°ì • ë˜ëŠ” ì•™ìƒë¸” ëª¨ë¸ ì ìš©

#### False Negative ìœ„í—˜ì„±
- **ë¬¸ì œ**: AI ì´ë¯¸ì§€ë¥¼ Realë¡œ ì˜¤ë¶„ë¥˜ (AI â†’ Real)
- **ì˜í–¥**: 
  - Deepfake ì´ë¯¸ì§€ê°€ ì‹¤ì œ ì´ë¯¸ì§€ë¡œ í†µê³¼ë  ìˆ˜ ìˆìŒ
  - ë³´ì•ˆ/ì‚¬ê¸° ë°©ì§€ ì‹œìŠ¤í…œì—ì„œ ì‹¬ê°í•œ ë¬¸ì œ
- **í˜„ì¬ ì„±ëŠ¥**: CNN 163ê°œ (10.8%), ViT 158ê°œ (10.5%)
- **ê°œì„  í•„ìš”**: AI í´ë˜ìŠ¤ íƒì§€ ì„±ëŠ¥ í–¥ìƒ (í˜„ì¬ F1: 87-90%)

#### Inference Latency
- **í˜„ì¬ ì„±ëŠ¥**:
  - CNN: í‰ê·  15ms (GPU), 120ms (CPU)
  - ViT: í‰ê·  45ms (GPU), 350ms (CPU)
- **ì‹¤ì„œë¹„ìŠ¤ ìš”êµ¬ì‚¬í•­**: 
  - ì‹¤ì‹œê°„ ì²˜ë¦¬: < 100ms (GPU ê¸°ì¤€)
  - ë°°ì¹˜ ì²˜ë¦¬: ì´ˆë‹¹ 100+ ì´ë¯¸ì§€
- **ê°œì„  í•„ìš”**: ëª¨ë¸ ìµœì í™” (ì–‘ìí™”, ONNX ë³€í™˜)

### 4. í¸í–¥ ê°€ëŠ¥ì„±

#### ë°ì´í„°ì…‹ í¸í–¥
- **ë¬¸ì œ**: íŠ¹ì • ë„ë©”ì¸(ì¸ë¬¼, í’ê²½ ë“±)ì— í¸í–¥ëœ ë°ì´í„°ì…‹
- **ì˜í–¥**: ë‹¤ë¥¸ ë„ë©”ì¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¼ë°˜í™” ì„±ëŠ¥ ì €í•˜
- **í•´ê²° ë°©ì•ˆ**: ë‹¤ì–‘í•œ ë„ë©”ì¸ ë°ì´í„° ì¶”ê°€

#### ìƒì„± ëª¨ë¸ í¸í–¥
- **ë¬¸ì œ**: íŠ¹ì • AI ìƒì„± ëª¨ë¸ì˜ ì´ë¯¸ì§€ë§Œ í•™ìŠµ
- **ì˜í–¥**: ìƒˆë¡œìš´ ìƒì„± ëª¨ë¸ì— ëŒ€í•œ íƒì§€ ì„±ëŠ¥ ì €í•˜
- **í•´ê²° ë°©ì•ˆ**: ë‹¤ì–‘í•œ ìƒì„± ëª¨ë¸ ë°ì´í„° ìˆ˜ì§‘ ë° ì§€ì†ì  ì—…ë°ì´íŠ¸

---

## ğŸ’¡ ê¸°ìˆ ì  ê³ ì°°

### ì™œ ì„±ëŠ¥ ì°¨ì´ê°€ 0.7%pë°–ì— ì•ˆ ë‚˜ëŠ”ê°€?

#### 1. **ë°ì´í„°ì…‹ íŠ¹ì„±**
- **ì´ë¯¸ì§€ í’ˆì§ˆ**: ëŒ€ë¶€ë¶„ì˜ ì´ë¯¸ì§€ê°€ ê³ í’ˆì§ˆë¡œ, ëª…í™•í•œ êµ¬ë¶„ì´ ê°€ëŠ¥
- **í´ë˜ìŠ¤ ë¶ˆê· í˜•**: Real í´ë˜ìŠ¤ê°€ ë§ì•„ ë‘ ëª¨ë¸ ëª¨ë‘ Real íƒì§€ì— ì§‘ì¤‘
- **ê²°ê³¼**: ë‘ ëª¨ë¸ ëª¨ë‘ ë†’ì€ ì„±ëŠ¥ ë‹¬ì„± (96%+), ì°¨ì´ê°€ ì‘ì„ ìˆ˜ë°–ì— ì—†ìŒ

#### 2. **ì‚¬ì „ í•™ìŠµ íš¨ê³¼**
- **CNN**: ImageNet ì‚¬ì „ í•™ìŠµìœ¼ë¡œ ì¶©ë¶„í•œ íŠ¹ì§• ì¶”ì¶œ ëŠ¥ë ¥ í™•ë³´
- **ViT**: ImageNet-21k ì‚¬ì „ í•™ìŠµìœ¼ë¡œ ë” í’ë¶€í•œ íŠ¹ì§• í•™ìŠµ
- **ì°¨ì´**: ì‚¬ì „ í•™ìŠµ íš¨ê³¼ê°€ í¬ë©´ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì°¨ì´ì˜ ì˜í–¥ì´ ìƒëŒ€ì ìœ¼ë¡œ ì‘ì•„ì§

#### 3. **íƒœìŠ¤í¬ ë³µì¡ë„**
- **ì´ì§„ ë¶„ë¥˜**: ë¹„êµì  ë‹¨ìˆœí•œ íƒœìŠ¤í¬ë¡œ, ë‘ ëª¨ë¸ ëª¨ë‘ ì¶©ë¶„í•œ ì„±ëŠ¥ ë‹¬ì„± ê°€ëŠ¥
- **ë³µì¡í•œ íƒœìŠ¤í¬**: ê°ì²´ íƒì§€, ì„¸ê·¸ë©˜í…Œì´ì…˜ ë“±ì—ì„œëŠ” ViTì˜ ìš°ìœ„ê°€ ë” ëª…í™•í•  ìˆ˜ ìˆìŒ

### ì™œ AI í´ë˜ìŠ¤ê°€ ë‚®ê²Œ ë‚˜ì˜¤ëŠ”ê°€?

#### 1. **í´ë˜ìŠ¤ ë¶ˆê· í˜•**
- **ë°ì´í„° ë¹„ìœ¨**: Real:Fake = 6:1
- **ì˜í–¥**: ëª¨ë¸ì´ Real í´ë˜ìŠ¤ì— ë” ë§ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬
- **í•´ê²°**: Weighted Loss ì ìš©ìœ¼ë¡œ ê°œì„ í–ˆì§€ë§Œ ì™„ì „í•œ í•´ê²°ì€ ì•„ë‹˜

#### 2. **AI ì´ë¯¸ì§€ì˜ ë‹¤ì–‘ì„±**
- **ë¬¸ì œ**: ë‹¤ì–‘í•œ ìƒì„± ëª¨ë¸, ìŠ¤íƒ€ì¼, í’ˆì§ˆì˜ AI ì´ë¯¸ì§€
- **ì˜í–¥**: ì¼ë¶€ ê³ í’ˆì§ˆ AI ì´ë¯¸ì§€ëŠ” ì‹¤ì œ ì´ë¯¸ì§€ì™€ êµ¬ë¶„ì´ ì–´ë ¤ì›€
- **í•´ê²°**: ë” ë‹¤ì–‘í•œ AI ì´ë¯¸ì§€ ë°ì´í„° ìˆ˜ì§‘ í•„ìš”

#### 3. **íŠ¹ì§• ì¶”ì¶œì˜ í•œê³„**
- **CNN**: ì§€ì—­ì  íŒ¨í„´ì— ì§‘ì¤‘í•˜ì—¬ ì „ì—­ì  ì¼ê´€ì„± ë¬¸ì œë¥¼ ë†“ì¹  ìˆ˜ ìˆìŒ
- **ViT**: ì „ì—­ì  ì»¨í…ìŠ¤íŠ¸ ì´í•´ë¡œ ê°œì„ í–ˆì§€ë§Œ ì—¬ì „íˆ í•œê³„ ì¡´ì¬

### ì™œ ViTê°€ ë” ì¢‹ì€ê°€?

#### 1. **ì „ì—­ì  ì»¨í…ìŠ¤íŠ¸ ì´í•´**
- **Self-Attention**: ì´ë¯¸ì§€ ì „ì²´ì˜ íŒ¨ì¹˜ ê°„ ê´€ê³„ë¥¼ ë™ì‹œì— í•™ìŠµ
- **AI ì´ë¯¸ì§€ íŠ¹ì„±**: ì „ì—­ì  ì¼ê´€ì„± ë¬¸ì œ(ë°°ê²½-ì „ê²½ ê²½ê³„, ì¡°ëª… ë¶ˆì¼ì¹˜) íƒì§€ì— ìœ ë¦¬
- **ê²°ê³¼**: False Positive ê°ì†Œ (224ê°œ â†’ 152ê°œ, 32% ê°œì„ )

#### 2. **ì„¸ë°€í•œ íŒ¨í„´ í•™ìŠµ**
- **ë³‘ë ¬ í•™ìŠµ**: ëª¨ë“  íŒ¨ì¹˜ ê°„ ê´€ê³„ë¥¼ ë³‘ë ¬ë¡œ í•™ìŠµ
- **ë¯¸ì„¸í•œ ì•„í‹°íŒ©íŠ¸**: ìƒì„± ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ì‘ì€ ì´ìƒ íŒ¨í„´ íƒì§€
- **ê²°ê³¼**: AI í´ë˜ìŠ¤ F1 Score í–¥ìƒ (87.42% â†’ 89.70%)

#### 3. **ì¼ë°˜í™” ì„±ëŠ¥**
- **ì‚¬ì „ í•™ìŠµ**: ImageNet-21kë¡œ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ í™œìš©
- **Validation-Test Gap**: ì‘ì€ ì°¨ì´ (0.22%p)ë¡œ ê³¼ì í•© ì €í•­
- **ê²°ê³¼**: ë” ì•ˆì •ì ì¸ ì„±ëŠ¥

---

## âš¡ ëª¨ë¸ ìµœì í™”

### ì–‘ìí™” (Quantization)

#### ì‹¤í—˜ ê²°ê³¼
| ëª¨ë¸ | ì •ë°€ë„ | ëª¨ë¸ í¬ê¸° | ì¶”ë¡  ì†ë„ (GPU) | Test Accuracy | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |
|-----|------|---------|---------------|---------------|------------|
| **ì›ë³¸** | FP32 | 128MB | 15ms | 96.32% | 512MB |
| **FP16** | FP16 | 64MB | 12ms | 96.28% | 256MB |
| **INT8** | INT8 | 32MB | 8ms | 95.8% | 128MB |

#### ê¶Œì¥ì‚¬í•­
- **FP16**: ì„±ëŠ¥ ì†ì‹¤ ìµœì†Œ(-0.04%p)í•˜ë©´ì„œ ì†ë„ 20% í–¥ìƒ â†’ **ê¶Œì¥**
- **INT8**: ì„±ëŠ¥ ì†ì‹¤ ìˆì§€ë§Œ ì†ë„ 47% í–¥ìƒ â†’ ì—£ì§€ ë””ë°”ì´ìŠ¤ì— ì í•©

### ONNX ë³€í™˜

#### ë³€í™˜ ê²°ê³¼
- **ëª¨ë¸ í¬ê¸°**: 128MB â†’ 120MB (ì•½ 6% ê°ì†Œ)
- **ì¶”ë¡  ì†ë„**: 
  - PyTorch: 15ms
  - ONNX Runtime (GPU): 10ms (33% í–¥ìƒ)
  - ONNX Runtime (CPU): 95ms (PyTorch CPU ëŒ€ë¹„ 21% í–¥ìƒ)

#### í™œìš© ë°©ì•ˆ
- **í”„ë¡œë•ì…˜ ë°°í¬**: ONNX Runtimeìœ¼ë¡œ ë” ë¹ ë¥¸ ì¶”ë¡ 
- **í¬ë¡œìŠ¤ í”Œë«í¼**: ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ë™ì¼í•œ ì„±ëŠ¥ ë³´ì¥

### Latency ë¹„êµ

| í™˜ê²½ | CNN (ResNet18) | ViT (ViT-Base) | ê°œì„ ìœ¨ |
|------|----------------|----------------|--------|
| **GPU (FP32)** | 15ms | 45ms | - |
| **GPU (FP16)** | 12ms | 35ms | 20-22% |
| **GPU (ONNX)** | 10ms | 28ms | 33-38% |
| **CPU (FP32)** | 120ms | 350ms | - |
| **CPU (ONNX)** | 95ms | 280ms | 21-20% |

### ìµœì í™” ê¶Œì¥ì‚¬í•­

1. **ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤**: CNN + FP16 + ONNX Runtime
2. **ë°°ì¹˜ ì²˜ë¦¬**: ViT + FP16 (ì •í™•ë„ ìš°ì„ )
3. **ì—£ì§€ ë””ë°”ì´ìŠ¤**: CNN + INT8 + ONNX Runtime

---

## ğŸ”’ ë³´ì•ˆ ë° ìœ¤ë¦¬

### ëª¨ë¸ ì˜¤íƒìœ¼ë¡œ ì¸í•œ í”¼í•´ ìµœì†Œí™”

#### 1. **ì„ê³„ê°’ ì¡°ì •**
- **í˜„ì¬**: ê¸°ë³¸ ì„ê³„ê°’ 0.5 ì‚¬ìš©
- **ê°œì„ **: í´ë˜ìŠ¤ë³„ ìµœì  ì„ê³„ê°’ íƒìƒ‰
  - Real í´ë˜ìŠ¤: ì„ê³„ê°’ 0.6 â†’ False Positive ê°ì†Œ
  - AI í´ë˜ìŠ¤: ì„ê³„ê°’ 0.4 â†’ False Negative ê°ì†Œ

#### 2. **ë¶ˆí™•ì‹¤ì„± ì¶”ì •**
- **êµ¬í˜„**: ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì„ ì‹ ë¢°ë„ë¡œ í™œìš©
- **ì •ì±…**: ì‹ ë¢°ë„ < 0.7ì¸ ê²½ìš° "ë¶ˆí™•ì‹¤"ë¡œ ë¶„ë¥˜í•˜ì—¬ ìˆ˜ë™ ê²€í† 

#### 3. **ì‚¬ìš©ì í”¼ë“œë°±**
- **êµ¬í˜„**: ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ìˆ˜ì§‘ ë° ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸
- **ëª©ì **: ì§€ì†ì ì¸ ëª¨ë¸ ì„±ëŠ¥ ê°œì„ 

### ì˜ë„ì¹˜ ì•Šì€ í¸í–¥ ê°€ëŠ¥ì„±

#### 1. **ë°ì´í„°ì…‹ í¸í–¥**
- **ë¬¸ì œ**: íŠ¹ì • ì¸ì¢…, ì„±ë³„, ì—°ë ¹ëŒ€ì— í¸í–¥ëœ ë°ì´í„°ì…‹
- **ëŒ€ì‘**: 
  - ë‹¤ì–‘í•œ ì¸êµ¬í†µê³„í•™ì  íŠ¹ì„±ì„ ê°€ì§„ ì´ë¯¸ì§€ ìˆ˜ì§‘
  - í¸í–¥ ê²€ì‚¬ ë° ë³´ì •

#### 2. **ë„ë©”ì¸ í¸í–¥**
- **ë¬¸ì œ**: íŠ¹ì • ë„ë©”ì¸(ì¸ë¬¼, í’ê²½ ë“±)ì— í¸í–¥
- **ëŒ€ì‘**: ë‹¤ì–‘í•œ ë„ë©”ì¸ ë°ì´í„° ì¶”ê°€ ë° ë„ë©”ì¸ ì ì‘ ê¸°ë²• ì ìš©

### ë¯¼ê° ì´ë¯¸ì§€ ì²˜ë¦¬ ì •ì±…

#### 1. **ê°œì¸ì •ë³´ ë³´í˜¸**
- **ì´ë¯¸ì§€ ì €ì¥**: ì¶”ë¡  í›„ ì¦‰ì‹œ ì‚­ì œ (ì„ì‹œ íŒŒì¼ ì‚¬ìš©)
- **ë¡œê·¸ ê¸°ë¡**: ì´ë¯¸ì§€ ë‚´ìš©ì€ ê¸°ë¡í•˜ì§€ ì•ŠìŒ, ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥

#### 2. **NSFW ì´ë¯¸ì§€ ì²˜ë¦¬**
- **í•„í„°ë§**: NSFW ì´ë¯¸ì§€ëŠ” ë³„ë„ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¶„ë¦¬
- **ì‚¬ìš©ì ê²½ê³ **: NSFW ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œ ê²½ê³  ë©”ì‹œì§€ í‘œì‹œ

#### 3. **ìœ¤ë¦¬ì  ì‚¬ìš© ê°€ì´ë“œë¼ì¸**
- **ëª©ì **: Deepfake íƒì§€ ë° AI ìƒì„± ì½˜í…ì¸  ì‹ë³„
- **ê¸ˆì§€ ì‚¬í•­**: 
  - ê°œì¸ ì‚¬ì§„ ë¬´ë‹¨ ë¶„ì„
  - ì°¨ë³„ì  ëª©ì ì˜ ì‚¬ìš©
  - ì‚¬ìƒí™œ ì¹¨í•´

### í–¥í›„ ê°œì„  ë°©í–¥

1. **ê³µì •ì„± ê²€ì¦**: ë‹¤ì–‘í•œ ê·¸ë£¹ì— ëŒ€í•œ ì„±ëŠ¥ ê· ë“±ì„± í™•ì¸
2. **íˆ¬ëª…ì„± í–¥ìƒ**: ëª¨ë¸ì˜ íŒë‹¨ ê·¼ê±° ì‹œê°í™” (Attention Map, Grad-CAM)
3. **ì‚¬ìš©ì ê¶Œë¦¬**: ì˜ˆì¸¡ ê²°ê³¼ì— ëŒ€í•œ ì„¤ëª… ì œê³µ ë° ì´ì˜ ì œê¸° ë©”ì»¤ë‹ˆì¦˜

---

## ğŸ‘¤ ê°œì¸ ê¸°ì—¬ë„ (Contribution)

ì´ í”„ë¡œì íŠ¸ëŠ” **100% ê°œì¸ í”„ë¡œì íŠ¸**ë¡œ, ëª¨ë“  ì‘ì—…ì„ ì§ì ‘ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.

### í”„ë¡œì íŠ¸ ë°°ê²½
- **ë¯¸ë‹ˆ í•´ì»¤í†¤ ì°¸ì—¬**: ì´ˆê¸° ë²„ì „ì„ í•´ì»¤í†¤ì—ì„œ ì‘ì—…í–ˆìœ¼ë‚˜, ì™„ì„±ë„ì™€ êµ¬ì¡°ì  ë¬¸ì œë¡œ ì¸í•´ **ì™„ì „íˆ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‘ì—…**
- **ì¬êµ¬ì¶• ëª©ì **: 
  - ë” ë‚˜ì€ ì½”ë“œ êµ¬ì¡° ë° ì•„í‚¤í…ì²˜ ì„¤ê³„
  - ì²´ê³„ì ì¸ ì‹¤í—˜ ì„¤ê³„ ë° ë¬¸ì„œí™”
  - í”„ë¡œë•ì…˜ ìˆ˜ì¤€ì˜ ë°°í¬ í™˜ê²½ êµ¬ì¶•

### ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ 
- âœ… **ë°ì´í„° ìˆ˜ì§‘**: 3ê°œ ë°ì´í„°ì…‹ í†µí•© (ì´ 70,190ê°œ ì´ë¯¸ì§€)
- âœ… **ë°ì´í„° ì „ì²˜ë¦¬**: Resize, Denoising, Histogram Equalization êµ¬í˜„
- âœ… **ë°ì´í„° ë¶„í• **: Stratified Splitìœ¼ë¡œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€í•˜ë©° Train/Val/Test ë¶„í• 
- âœ… **EDA**: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”

### ëª¨ë¸ ì„¤ê³„ ë° ì‹¤í—˜ 
- âœ… **ëª¨ë¸ ì„ íƒ**: CNN (ResNet18) ë° ViT (ViT-Base) ì•„í‚¤í…ì²˜ ì„ íƒ ë° êµ¬í˜„
- âœ… **ì‹¤í—˜ ì„¤ê³„**: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì „ëµ ìˆ˜ë¦½
- âœ… **Ablation Study**: ë°ì´í„° ì¦ê°•, ì „ì²˜ë¦¬, ì†ì‹¤ í•¨ìˆ˜ íš¨ê³¼ ë¶„ì„
- âœ… **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: Batch Size, Learning Rate, Optimizer ìµœì í™”

### í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• 
- âœ… **í•™ìŠµ ì½”ë“œ**: PyTorch ê¸°ë°˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- âœ… **í‰ê°€ ì‹œìŠ¤í…œ**: Accuracy, Precision, Recall, F1, Confusion Matrix êµ¬í˜„
- âœ… **Early Stopping**: ê³¼ì í•© ë°©ì§€ ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„
- âœ… **ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬**: Best/Latest ëª¨ë¸ ìë™ ì €ì¥

### ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ 
- âœ… **Streamlit UI**: ì›¹ ë°ëª¨ ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„ ë° êµ¬í˜„
- âœ… **FastAPI ë°±ì—”ë“œ**: RESTful API ì„œë²„ êµ¬ì¶•
- âœ… **í”„ë¡ íŠ¸ì—”ë“œ-ë°±ì—”ë“œ ì—°ê²°**: API í†µì‹  ë° ì—ëŸ¬ ì²˜ë¦¬ êµ¬í˜„
- âœ… **ì‚¬ìš©ì ê²½í—˜**: ì´ë¯¸ì§€ ì—…ë¡œë“œ, ê²°ê³¼ ì‹œê°í™”, í™•ë¥  ë¶„í¬ í‘œì‹œ

### ë°°í¬ ë° ì¸í”„ë¼ 
- âœ… **Docker**: Dockerfile ì‘ì„± ë° Docker Compose êµ¬ì„±
- âœ… **HuggingFace Spaces**: ë°°í¬ í™˜ê²½ êµ¬ì„± ë° ë°°í¬ ìˆ˜í–‰
- âœ… **ë°°í¬ ë¬¸ì œ í•´ê²°**: 403 ì—ëŸ¬, íŒŒì¼ ì‹œìŠ¤í…œ ê¶Œí•œ ë“± ì´ìŠˆ í•´ê²°
- âœ… **CI/CD**: GitHub Actions ì›Œí¬í”Œë¡œìš° ì„¤ê³„ (í–¥í›„ êµ¬í˜„ ì˜ˆì •)

### ë¬¸ì„œí™” 
- âœ… **README**: ë¬¸ì„œ ì§ì ‘ ì‘ì„± í›„ LLM ì •ë¦¬ ë„ì›€ ë°›ìŒ (ì´ˆì•ˆ ì‘ì„± ë° êµ¬ì¡° ì„¤ê³„ëŠ” ë³¸ì¸ ìˆ˜í–‰)
- âœ… **ì‹¤í—˜ ë³´ê³ ì„œ**: ìƒì„¸í•œ ì‹¤í—˜ ë¶„ì„ ë° ê²°ê³¼ í•´ì„
- âœ… **ì½”ë“œ ì£¼ì„**: ì£¼ìš” í•¨ìˆ˜ ë° í´ë˜ìŠ¤ì— í•œêµ­ì–´ ì£¼ì„ ì¶”ê°€
- âœ… **ë°°í¬ ê°€ì´ë“œ**: Docker, HuggingFace Spaces ë°°í¬ ê°€ì´ë“œ ì‘ì„±

### ì¶”ê°€ ê¸°ëŠ¥ ê°œë°œ
- âœ… **ë°°ì¹˜ ì¶”ë¡ **: ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ì²˜ë¦¬ ê¸°ëŠ¥ êµ¬í˜„
- âœ… **ëª¨ë¸ ìµœì í™”**: ì–‘ìí™”, ONNX ë³€í™˜ ì—°êµ¬ ë° êµ¬í˜„
- âœ… **Explainability**: Grad-CAM, Attention Map ì‹œê°í™” ì¤€ë¹„ (í–¥í›„ êµ¬í˜„ ì˜ˆì •)

### ê¸°ìˆ  ìŠ¤íƒ ì„ íƒ ë° í•™ìŠµ
- âœ… **í”„ë ˆì„ì›Œí¬ ì„ íƒ**: PyTorch, Streamlit, FastAPI ì„ íƒ ë° í•™ìŠµ
- âœ… **ëª¨ë¸ ì•„í‚¤í…ì²˜ ì´í•´**: ResNet, Vision Transformer ì´ë¡  í•™ìŠµ ë° êµ¬í˜„
- âœ… **ë°°í¬ í”Œë«í¼ í•™ìŠµ**: Docker, HuggingFace Spaces ì‚¬ìš©ë²• í•™ìŠµ

---

## ğŸ¯ ì´ í”„ë¡œì íŠ¸ê°€ ì¦ëª…í•˜ëŠ” ì—­ëŸ‰

### 1. End-to-End AI ê°œë°œ ì—­ëŸ‰
**ì¦ëª… ë‚´ìš©**:
- ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ë°°í¬ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- EDA â†’ ì „ì²˜ë¦¬ â†’ ëª¨ë¸ë§ â†’ ì‹¤í—˜ â†’ í‰ê°€ â†’ ë°°í¬ ì „ ê³¼ì • ìˆ˜í–‰
- ì‹¤ì œ ì„œë¹„ìŠ¤ ê°€ëŠ¥í•œ ìˆ˜ì¤€ì˜ ì™„ì„±ë„

**ëŒ€ê¸°ì—…ì—ì„œì˜ ê°€ì¹˜**:
- AI í”„ë¡œì íŠ¸ë¥¼ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì±…ì„ì§ˆ ìˆ˜ ìˆëŠ” ì—­ëŸ‰
- ë°ì´í„°ë¶€í„° ë°°í¬ê¹Œì§€ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì´í•´

### 2. ML ì‹¤í—˜ ì„¤ê³„ ëŠ¥ë ¥
**ì¦ëª… ë‚´ìš©**:
- ì²´ê³„ì ì¸ Ablation Study ì„¤ê³„ ë° ìˆ˜í–‰
- Design Decision ë…¼ë¦¬ì  ê·¼ê±° ì œì‹œ
- í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ í•´ê²° (Weighted Loss, Stratified Split)
- í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì „ëµ ìˆ˜ë¦½

**ëŒ€ê¸°ì—…ì—ì„œì˜ ê°€ì¹˜**:
- ì‹¤í—˜ ì„¤ê³„ ë° ê²°ê³¼ í•´ì„ ëŠ¥ë ¥
- ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì²´ê³„ì  ì ‘ê·¼
- ì¬í˜„ ê°€ëŠ¥í•œ ì‹¤í—˜ í™˜ê²½ êµ¬ì¶•

### 3. ì‹œìŠ¤í…œ ì„¤ê³„ ëŠ¥ë ¥
**ì¦ëª… ë‚´ìš©**:
- ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„
- RESTful API ì„¤ê³„ ë° êµ¬í˜„
- Docker ê¸°ë°˜ ì»¨í…Œì´ë„ˆí™”
- ì›¹ ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„ ë° êµ¬í˜„

**ëŒ€ê¸°ì—…ì—ì„œì˜ ê°€ì¹˜**:
- ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„ ëŠ¥ë ¥
- ë°±ì—”ë“œ/í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ ì—­ëŸ‰
- ì¸í”„ë¼ êµ¬ì„± ë° ë°°í¬ ê²½í—˜

### 4. ë¬¸ì„œí™” ëŠ¥ë ¥
**ì¦ëª… ë‚´ìš©**:
- ëŒ€ê¸°ì—… ìˆ˜ì¤€ì˜ êµ¬ì¡°ì  README ì‘ì„±
- ìƒì„¸í•œ ì‹¤í—˜ ë³´ê³ ì„œ ì‘ì„±
- ì½”ë“œ ì£¼ì„ ë° ë¬¸ì„œí™”
- ë°°í¬ ê°€ì´ë“œ ì‘ì„±

**ëŒ€ê¸°ì—…ì—ì„œì˜ ê°€ì¹˜**:
- ê¸°ìˆ  ë¬¸ì„œ ì‘ì„± ëŠ¥ë ¥
- ì§€ì‹ ê³µìœ  ë° ì „ë‹¬ ëŠ¥ë ¥
- í”„ë¡œì íŠ¸ ê´€ë¦¬ ì—­ëŸ‰

### 5. í”„ë¡œë•ì…˜ ê³ ë ¤ ì—­ëŸ‰
**ì¦ëª… ë‚´ìš©**:
- ëª¨ë¸ ìµœì í™” (ì–‘ìí™”, ONNX ë³€í™˜)
- Inference Latency ê°œì„ 
- ëª¨ë¸ í•œê³„ ë° ìœ„í—˜ ìš”ì†Œ ë¶„ì„
- ë³´ì•ˆ ë° ìœ¤ë¦¬ ê³ ë ¤

**ëŒ€ê¸°ì—…ì—ì„œì˜ ê°€ì¹˜**:
- ì‹¤ì œ ì„œë¹„ìŠ¤ ìš´ì˜ ê³ ë ¤ ëŠ¥ë ¥
- ì„±ëŠ¥ ìµœì í™” ê²½í—˜
- ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë° ëŒ€ì‘ ëŠ¥ë ¥

### 6. ë¬¸ì œ í•´ê²° ëŠ¥ë ¥
**ì¦ëª… ë‚´ìš©**:
- ë°°í¬ ê³¼ì •ì—ì„œ ë°œìƒí•œ ë¬¸ì œ í•´ê²° (403 ì—ëŸ¬, íŒŒì¼ ì‹œìŠ¤í…œ ê¶Œí•œ)
- í™˜ê²½ë³„ ì´ìŠˆ í•´ê²° (macOS multiprocessing, Docker ë¹Œë“œ)
- ëª¨ë¸ ìš©ëŸ‰ ì œí•œ ëŒ€ì‘ (HuggingFace Spaces 1GB ì œí•œ)

**ëŒ€ê¸°ì—…ì—ì„œì˜ ê°€ì¹˜**:
- ë¬¸ì œ ë¶„ì„ ë° í•´ê²° ëŠ¥ë ¥
- ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œì˜ ì ì‘ë ¥
- ì œì•½ ì¡°ê±´ ë‚´ì—ì„œ ìµœì í™” ëŠ¥ë ¥

### 7. ì§€ì†ì  í•™ìŠµ ë° ê°œì„ 
**ì¦ëª… ë‚´ìš©**:
- ìµœì‹  ê¸°ìˆ  ìŠ¤íƒ í•™ìŠµ (Vision Transformer)
- ëª¨ë¸ ìµœì í™” ê¸°ë²• ì—°êµ¬ (Quantization, ONNX)
- ë°°í¬ í”Œë«í¼ í•™ìŠµ (HuggingFace Spaces, Docker)

**ëŒ€ê¸°ì—…ì—ì„œì˜ ê°€ì¹˜**:
- ë¹ ë¥¸ í•™ìŠµ ëŠ¥ë ¥
- ê¸°ìˆ  íŠ¸ë Œë“œ íŒŒì•… ë° ì ìš©
- ì§€ì†ì  ê°œì„  ì˜ì§€

---

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì‹¤í–‰

### ìš”êµ¬ì‚¬í•­
- Python 3.11+
- CUDA ì§€ì› GPU (ì„ íƒì‚¬í•­, CPUë„ ê°€ëŠ¥)

### ì„¤ì¹˜

1. **ì €ì¥ì†Œ í´ë¡ **
```bash
git clone https://github.com/yanggangyiplus/Ai-image-detector.git
cd Ai-image-detector
```

2. **ì˜ì¡´ì„± ì„¤ì¹˜**
```bash
pip install -r requirements.txt
```

3. **ë°ì´í„° ì¤€ë¹„**
   - ë°ì´í„°ì…‹ì„ `data/raw/` í´ë”ì— ë°°ì¹˜
   - ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: `notebooks/preprocessing.ipynb`

### ëª¨ë¸ í•™ìŠµ

#### CNN ëª¨ë¸ í•™ìŠµ
```bash
python scripts/run_cnn_training.py
```

#### ViT ëª¨ë¸ í•™ìŠµ
```bash
python scripts/run_vit_training.py
```

### ì¶”ë¡ 

#### ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ 
```bash
python examples/single_image_inference.py --image_path path/to/image.jpg
```

#### ë°°ì¹˜ ì¶”ë¡ 
```bash
python examples/batch_inference.py --input_dir path/to/images/
```

ìì„¸í•œ ì‚¬ìš© ë°©ë²•ì€ [docs/INSTALL_AND_RUN.md](docs/INSTALL_AND_RUN.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
Ai-image-detector/
â”œâ”€â”€ app/                    # ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚   â”œâ”€â”€ web_demo.py        # Streamlit ì›¹ ë°ëª¨
â”‚   â”œâ”€â”€ api.py             # FastAPI ë°±ì—”ë“œ
â”‚   â””â”€â”€ templates/         # HTML í…œí”Œë¦¿
â”‚
â”œâ”€â”€ configs/               # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ config_cnn.yaml
â”‚   â”œâ”€â”€ config_vit.yaml
â”‚   â””â”€â”€ config_eval.yaml
â”‚
â”œâ”€â”€ data/                  # ë°ì´í„°
â”‚   â”œâ”€â”€ raw/              # ì›ë³¸ ë°ì´í„°
â”‚   â”œâ”€â”€ processed/        # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â”œâ”€â”€ train/            # í•™ìŠµ ë°ì´í„°
â”‚   â”œâ”€â”€ val/              # ê²€ì¦ ë°ì´í„°
â”‚   â””â”€â”€ test/             # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â”‚
â”œâ”€â”€ deployment/            # ë°°í¬ ê´€ë ¨
â”‚   â”œâ”€â”€ docker/           # Docker íŒŒì¼
â”‚   â””â”€â”€ huggingface/      # HuggingFace Spaces ë°°í¬
â”‚
â”œâ”€â”€ experiments/           # ì‹¤í—˜ ê²°ê³¼
â”‚   â”œâ”€â”€ checkpoints/      # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ logs/            # í•™ìŠµ ë¡œê·¸
â”‚   â”œâ”€â”€ results/         # ê²°ê³¼ ê·¸ë˜í”„
â”‚   â””â”€â”€ reports/         # ì‹¤í—˜ ë³´ê³ ì„œ
â”‚
â”œâ”€â”€ notebooks/            # Jupyter ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ EDA.ipynb        # íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
â”‚   â”œâ”€â”€ preprocessing.ipynb
â”‚   â”œâ”€â”€ model_CNN.ipynb
â”‚   â”œâ”€â”€ model_ViT.ipynb
â”‚   â””â”€â”€ model_compare.ipynb
â”‚
â”œâ”€â”€ scripts/              # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ run_cnn_training.py
â”‚   â”œâ”€â”€ run_vit_training.py
â”‚   â”œâ”€â”€ run_streamlit.sh
â”‚   â””â”€â”€ run_api.sh
â”‚
â”œâ”€â”€ src/                  # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ data/            # ë°ì´í„° ì²˜ë¦¬
â”‚   â”œâ”€â”€ models/          # ëª¨ë¸ ì •ì˜
â”‚   â”œâ”€â”€ training/        # í•™ìŠµ ê´€ë ¨
â”‚   â”œâ”€â”€ inference/       # ì¶”ë¡  ê´€ë ¨
â”‚   â””â”€â”€ utils/           # ìœ í‹¸ë¦¬í‹°
â”‚
â”œâ”€â”€ examples/            # ì˜ˆì œ ì½”ë“œ
â”œâ”€â”€ docs/               # ë¬¸ì„œ
â”œâ”€â”€ README.md           # í”„ë¡œì íŠ¸ ì„¤ëª…
â””â”€â”€ requirements.txt    # ì˜ì¡´ì„± ëª©ë¡
```

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

---

## ğŸ‘¤ ì‘ì„±ì

**yanggangyi**

- GitHub: [@yanggangyiplus](https://github.com/yanggangyiplus)
- HuggingFace: [@yanggangyi](https://huggingface.co/yanggangyi)

---

## ğŸ™ ê°ì‚¬ì˜ ë§

- PyTorch íŒ€
- HuggingFace íŒ€
- Streamlit íŒ€
- ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹°

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [ì‹¤í—˜ ë³´ê³ ì„œ](experiments/reports/experiment_report.md)
- [ë°°í¬ ê°€ì´ë“œ](deployment/DEPLOYMENT.md)
- [ì„¤ì¹˜ ë° ì‹¤í–‰ ê°€ì´ë“œ](docs/INSTALL_AND_RUN.md)

