{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” AI ìƒì„± ì´ë¯¸ì§€ì™€ ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì„ íƒìƒ‰í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ëª©í‘œ\n",
        "- ë°ì´í„° ë¶„í¬ ë° í´ë˜ìŠ¤ ë¶ˆê· í˜• íŒŒì•…\n",
        "- ì´ë¯¸ì§€ í•´ìƒë„ ë° í’ˆì§ˆ ë¶„ì„\n",
        "- ë…¸ì´ì¦ˆ ìˆ˜ì¤€ í™•ì¸\n",
        "- ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™”\n",
        "- \"ì™œ ì´ ë°ì´í„°ê°€ ì–´ë ¤ìš´ê°€?\" ë¬¸ì œ ì •ì˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ì‹œê°í™” ì„¤ì •\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ë°ì´í„° ê²½ë¡œ ì„¤ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
        "DATA_DIR = Path(\"../data\")\n",
        "RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
        "PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
        "TRAIN_DIR = DATA_DIR / \"train\"\n",
        "VAL_DIR = DATA_DIR / \"val\"\n",
        "TEST_DIR = DATA_DIR / \"test\"\n",
        "\n",
        "# ë¶„ì„í•  ë°ì´í„°ì…‹ ì„ íƒ (raw ë˜ëŠ” processed)\n",
        "ANALYZE_RAW = True  # True: ì›ë³¸ ë°ì´í„° ë¶„ì„, False: ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¶„ì„\n",
        "\n",
        "if ANALYZE_RAW:\n",
        "    BASE_DIR = RAW_DATA_DIR\n",
        "    print(\"ğŸ“ ì›ë³¸ ë°ì´í„° ë¶„ì„ ëª¨ë“œ\")\n",
        "else:\n",
        "    BASE_DIR = PROCESSED_DATA_DIR / \"all\"\n",
        "    print(\"ğŸ“ ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¶„ì„ ëª¨ë“œ\")\n",
        "\n",
        "print(f\"ë¶„ì„ ëŒ€ìƒ ê²½ë¡œ: {BASE_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ê¸°ë³¸ ë°ì´í„° í†µê³„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collect_image_statistics(base_dir):\n",
        "    \"\"\"\n",
        "    ì´ë¯¸ì§€ íŒŒì¼ í†µê³„ ìˆ˜ì§‘\n",
        "    \n",
        "    Returns:\n",
        "        stats: ì´ë¯¸ì§€ í†µê³„ ë”•ì…”ë„ˆë¦¬\n",
        "    \"\"\"\n",
        "    stats = {\n",
        "        'total_images': 0,\n",
        "        'by_category': {},\n",
        "        'by_dataset': {},\n",
        "        'image_paths': [],\n",
        "        'categories': [],\n",
        "        'datasets': []\n",
        "    }\n",
        "    \n",
        "    # ì´ë¯¸ì§€ í™•ì¥ì\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}\n",
        "    \n",
        "    # ë°ì´í„°ì…‹ë³„ë¡œ íƒìƒ‰\n",
        "    if BASE_DIR.name == \"raw\":\n",
        "        # ì›ë³¸ ë°ì´í„°: dataset_1, dataset_2, dataset_3 êµ¬ì¡°\n",
        "        for dataset_dir in BASE_DIR.iterdir():\n",
        "            if not dataset_dir.is_dir():\n",
        "                continue\n",
        "            \n",
        "            dataset_name = dataset_dir.name\n",
        "            dataset_count = 0\n",
        "            \n",
        "            # ì¬ê·€ì ìœ¼ë¡œ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°\n",
        "            for img_path in dataset_dir.rglob(\"*\"):\n",
        "                if img_path.suffix.lower() in image_extensions:\n",
        "                    stats['total_images'] += 1\n",
        "                    dataset_count += 1\n",
        "                    stats['image_paths'].append(img_path)\n",
        "                    \n",
        "                    # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ\n",
        "                    category = None\n",
        "                    for part in img_path.parts:\n",
        "                        part_lower = part.lower()\n",
        "                        if part_lower in ['real', 'authentic']:\n",
        "                            category = 'real'\n",
        "                            break\n",
        "                        elif part_lower in ['fake', 'ai', 'generated']:\n",
        "                            category = 'fake'\n",
        "                            break\n",
        "                    \n",
        "                    if category:\n",
        "                        stats['categories'].append(category)\n",
        "                        if category not in stats['by_category']:\n",
        "                            stats['by_category'][category] = 0\n",
        "                        stats['by_category'][category] += 1\n",
        "                    \n",
        "                    stats['datasets'].append(dataset_name)\n",
        "            \n",
        "            if dataset_count > 0:\n",
        "                stats['by_dataset'][dataset_name] = dataset_count\n",
        "    \n",
        "    else:\n",
        "        # ì „ì²˜ë¦¬ëœ ë°ì´í„°: ì¹´í…Œê³ ë¦¬ë³„ ë””ë ‰í† ë¦¬ êµ¬ì¡°\n",
        "        for category_dir in BASE_DIR.iterdir():\n",
        "            if not category_dir.is_dir():\n",
        "                continue\n",
        "            \n",
        "            category = category_dir.name\n",
        "            category_count = 0\n",
        "            \n",
        "            for img_path in category_dir.glob(\"*\"):\n",
        "                if img_path.suffix.lower() in image_extensions:\n",
        "                    stats['total_images'] += 1\n",
        "                    category_count += 1\n",
        "                    stats['image_paths'].append(img_path)\n",
        "                    stats['categories'].append(category)\n",
        "                    \n",
        "                    # ë°ì´í„°ì…‹ ì´ë¦„ ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)\n",
        "                    dataset_name = img_path.name.split('_')[0] if '_' in img_path.name else 'unknown'\n",
        "                    stats['datasets'].append(dataset_name)\n",
        "            \n",
        "            stats['by_category'][category] = category_count\n",
        "    \n",
        "    return stats\n",
        "\n",
        "# í†µê³„ ìˆ˜ì§‘\n",
        "print(\"ğŸ“Š ì´ë¯¸ì§€ í†µê³„ ìˆ˜ì§‘ ì¤‘...\")\n",
        "stats = collect_image_statistics(BASE_DIR)\n",
        "\n",
        "print(f\"\\nâœ… í†µê³„ ìˆ˜ì§‘ ì™„ë£Œ!\")\n",
        "print(f\"   ì´ ì´ë¯¸ì§€ ìˆ˜: {stats['total_images']:,}ê°œ\")\n",
        "print(f\"\\nğŸ“ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:\")\n",
        "for cat, count in stats['by_category'].items():\n",
        "    percentage = (count / stats['total_images']) * 100\n",
        "    print(f\"   - {cat}: {count:,}ê°œ ({percentage:.1f}%)\")\n",
        "\n",
        "if stats['by_dataset']:\n",
        "    print(f\"\\nğŸ“¦ ë°ì´í„°ì…‹ë³„ ë¶„í¬:\")\n",
        "    for ds, count in stats['by_dataset'].items():\n",
        "        percentage = (count / stats['total_images']) * 100\n",
        "        print(f\"   - {ds}: {count:,}ê°œ ({percentage:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í´ë˜ìŠ¤ ë¶ˆê· í˜• ì‹œê°í™”\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# 1. ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬ ë§‰ëŒ€ ê·¸ë˜í”„\n",
        "categories = list(stats['by_category'].keys())\n",
        "counts = list(stats['by_category'].values())\n",
        "colors = ['#3498db' if cat == 'real' else '#e74c3c' for cat in categories]\n",
        "\n",
        "axes[0].bar(categories, counts, color=colors)\n",
        "axes[0].set_title('í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ë¶„í¬', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('ì´ë¯¸ì§€ ìˆ˜', fontsize=12)\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# ê°’ í‘œì‹œ\n",
        "for i, (cat, count) in enumerate(zip(categories, counts)):\n",
        "    axes[0].text(i, count, f'{count:,}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "# 2. íŒŒì´ ì°¨íŠ¸\n",
        "axes[1].pie(counts, labels=categories, autopct='%1.1f%%', colors=colors, startangle=90)\n",
        "axes[1].set_title('í´ë˜ìŠ¤ ë¹„ìœ¨', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ë¶ˆê· í˜• ë¹„ìœ¨ ê³„ì‚°\n",
        "if len(counts) >= 2:\n",
        "    imbalance_ratio = max(counts) / min(counts)\n",
        "    print(f\"\\nğŸ“ˆ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¹„ìœ¨: {imbalance_ratio:.2f}:1\")\n",
        "    print(f\"   (ê°€ì¥ ë§ì€ í´ë˜ìŠ¤ / ê°€ì¥ ì ì€ í´ë˜ìŠ¤)\")\n",
        "    \n",
        "    if imbalance_ratio > 5:\n",
        "        print(\"   âš ï¸  ì‹¬ê°í•œ ë¶ˆê· í˜•: ë°ì´í„° ì¦ê°• ë˜ëŠ” ìƒ˜í”Œë§ ì „ëµ í•„ìš”\")\n",
        "    elif imbalance_ratio > 3:\n",
        "        print(\"   âš ï¸  ì¤‘ê°„ ì •ë„ ë¶ˆê· í˜•: ë°ì´í„° ì¦ê°• ê¶Œì¥\")\n",
        "    elif imbalance_ratio > 2:\n",
        "        print(\"   âš ï¸  ì•½ê°„ì˜ ë¶ˆê· í˜•: ì£¼ì˜ í•„ìš”\")\n",
        "    else:\n",
        "        print(\"   âœ… ê· í˜•ì´ ì˜ ë§ì¶°ì ¸ ìˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ì´ë¯¸ì§€ í•´ìƒë„ ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_image_resolutions(image_paths, sample_size=1000):\n",
        "    \"\"\"\n",
        "    ì´ë¯¸ì§€ í•´ìƒë„ ë¶„ì„\n",
        "    \n",
        "    Args:\n",
        "        image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "        sample_size: ë¶„ì„í•  ìƒ˜í”Œ í¬ê¸° (ì „ì²´ê°€ ë„ˆë¬´ ë§ì„ ê²½ìš°)\n",
        "    \"\"\"\n",
        "    resolutions = []\n",
        "    widths = []\n",
        "    heights = []\n",
        "    aspect_ratios = []\n",
        "    \n",
        "    # ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´ ì¼ë¶€ë§Œ ë¶„ì„)\n",
        "    if len(image_paths) > sample_size:\n",
        "        import random\n",
        "        random.seed(42)\n",
        "        sampled_paths = random.sample(image_paths, sample_size)\n",
        "        print(f\"âš ï¸  ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ë§ì•„ {sample_size}ê°œë§Œ ìƒ˜í”Œë§í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.\")\n",
        "    else:\n",
        "        sampled_paths = image_paths\n",
        "    \n",
        "    print(f\"ğŸ“ {len(sampled_paths)}ê°œ ì´ë¯¸ì§€ì˜ í•´ìƒë„ ë¶„ì„ ì¤‘...\")\n",
        "    \n",
        "    for img_path in tqdm(sampled_paths, desc=\"í•´ìƒë„ ë¶„ì„\"):\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                width, height = img.size\n",
        "                resolutions.append((width, height))\n",
        "                widths.append(width)\n",
        "                heights.append(height)\n",
        "                aspect_ratios.append(width / height if height > 0 else 1.0)\n",
        "        except Exception as e:\n",
        "            continue\n",
        "    \n",
        "    return {\n",
        "        'resolutions': resolutions,\n",
        "        'widths': widths,\n",
        "        'heights': heights,\n",
        "        'aspect_ratios': aspect_ratios\n",
        "    }\n",
        "\n",
        "# í•´ìƒë„ ë¶„ì„\n",
        "resolution_stats = analyze_image_resolutions(stats['image_paths'])\n",
        "\n",
        "# í†µê³„ ì¶œë ¥\n",
        "print(f\"\\nâœ… í•´ìƒë„ ë¶„ì„ ì™„ë£Œ!\")\n",
        "print(f\"\\nğŸ“ í•´ìƒë„ í†µê³„:\")\n",
        "print(f\"   í‰ê·  ë„ˆë¹„: {np.mean(resolution_stats['widths']):.0f}px\")\n",
        "print(f\"   í‰ê·  ë†’ì´: {np.mean(resolution_stats['heights']):.0f}px\")\n",
        "print(f\"   ìµœì†Œ í•´ìƒë„: {min(resolution_stats['widths'])}x{min(resolution_stats['heights'])}\")\n",
        "print(f\"   ìµœëŒ€ í•´ìƒë„: {max(resolution_stats['widths'])}x{max(resolution_stats['heights'])}\")\n",
        "print(f\"   í‰ê·  ì¢…íš¡ë¹„: {np.mean(resolution_stats['aspect_ratios']):.2f}\")\n",
        "\n",
        "# ê°€ì¥ í”í•œ í•´ìƒë„\n",
        "resolution_counter = Counter(resolution_stats['resolutions'])\n",
        "most_common = resolution_counter.most_common(5)\n",
        "print(f\"\\n   ê°€ì¥ í”í•œ í•´ìƒë„ Top 5:\")\n",
        "for res, count in most_common:\n",
        "    print(f\"     - {res[0]}x{res[1]}: {count}ê°œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•´ìƒë„ ë¶„í¬ ì‹œê°í™”\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. ë„ˆë¹„ ë¶„í¬\n",
        "axes[0, 0].hist(resolution_stats['widths'], bins=50, color='#3498db', alpha=0.7)\n",
        "axes[0, 0].set_title('ì´ë¯¸ì§€ ë„ˆë¹„ ë¶„í¬', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('ë„ˆë¹„ (px)')\n",
        "axes[0, 0].set_ylabel('ë¹ˆë„')\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "axes[0, 0].axvline(np.mean(resolution_stats['widths']), color='red', linestyle='--', \n",
        "                   label=f'í‰ê· : {np.mean(resolution_stats[\"widths\"]):.0f}px')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# 2. ë†’ì´ ë¶„í¬\n",
        "axes[0, 1].hist(resolution_stats['heights'], bins=50, color='#e74c3c', alpha=0.7)\n",
        "axes[0, 1].set_title('ì´ë¯¸ì§€ ë†’ì´ ë¶„í¬', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('ë†’ì´ (px)')\n",
        "axes[0, 1].set_ylabel('ë¹ˆë„')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "axes[0, 1].axvline(np.mean(resolution_stats['heights']), color='red', linestyle='--',\n",
        "                   label=f'í‰ê· : {np.mean(resolution_stats[\"heights\"]):.0f}px')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# 3. ì¢…íš¡ë¹„ ë¶„í¬\n",
        "axes[1, 0].hist(resolution_stats['aspect_ratios'], bins=50, color='#2ecc71', alpha=0.7)\n",
        "axes[1, 0].set_title('ì¢…íš¡ë¹„ ë¶„í¬', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('ì¢…íš¡ë¹„ (ë„ˆë¹„/ë†’ì´)')\n",
        "axes[1, 0].set_ylabel('ë¹ˆë„')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "axes[1, 0].axvline(np.mean(resolution_stats['aspect_ratios']), color='red', linestyle='--',\n",
        "                   label=f'í‰ê· : {np.mean(resolution_stats[\"aspect_ratios\"]):.2f}')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# 4. í•´ìƒë„ ì‚°ì ë„\n",
        "sample_indices = np.random.choice(len(resolution_stats['widths']), \n",
        "                                 min(1000, len(resolution_stats['widths'])), \n",
        "                                 replace=False)\n",
        "sample_widths = [resolution_stats['widths'][i] for i in sample_indices]\n",
        "sample_heights = [resolution_stats['heights'][i] for i in sample_indices]\n",
        "\n",
        "axes[1, 1].scatter(sample_widths, sample_heights, alpha=0.3, s=10)\n",
        "axes[1, 1].set_title('í•´ìƒë„ ë¶„í¬ (ë„ˆë¹„ vs ë†’ì´)', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('ë„ˆë¹„ (px)')\n",
        "axes[1, 1].set_ylabel('ë†’ì´ (px)')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ (ë…¸ì´ì¦ˆ, ë°ê¸°, ëŒ€ë¹„)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_image_quality(image_paths, sample_size=500):\n",
        "    \"\"\"\n",
        "    ì´ë¯¸ì§€ í’ˆì§ˆ ì§€í‘œ ë¶„ì„\n",
        "    \n",
        "    Returns:\n",
        "        quality_stats: í’ˆì§ˆ í†µê³„ ë”•ì…”ë„ˆë¦¬\n",
        "    \"\"\"\n",
        "    brightness_values = []\n",
        "    contrast_values = []\n",
        "    sharpness_values = []\n",
        "    \n",
        "    # ìƒ˜í”Œë§\n",
        "    if len(image_paths) > sample_size:\n",
        "        import random\n",
        "        random.seed(42)\n",
        "        sampled_paths = random.sample(image_paths, sample_size)\n",
        "    else:\n",
        "        sampled_paths = image_paths\n",
        "    \n",
        "    print(f\"ğŸ” {len(sampled_paths)}ê°œ ì´ë¯¸ì§€ì˜ í’ˆì§ˆ ë¶„ì„ ì¤‘...\")\n",
        "    \n",
        "    for img_path in tqdm(sampled_paths, desc=\"í’ˆì§ˆ ë¶„ì„\"):\n",
        "        try:\n",
        "            img = cv2.imread(str(img_path))\n",
        "            if img is None:\n",
        "                continue\n",
        "            \n",
        "            # BGRì„ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            \n",
        "            # ë°ê¸° (í‰ê·  í”½ì…€ ê°’)\n",
        "            brightness = np.mean(gray)\n",
        "            brightness_values.append(brightness)\n",
        "            \n",
        "            # ëŒ€ë¹„ (í‘œì¤€í¸ì°¨)\n",
        "            contrast = np.std(gray)\n",
        "            contrast_values.append(contrast)\n",
        "            \n",
        "            # ì„ ëª…ë„ (Laplacian ë¶„ì‚°)\n",
        "            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "            sharpness_values.append(laplacian_var)\n",
        "            \n",
        "        except Exception as e:\n",
        "            continue\n",
        "    \n",
        "    return {\n",
        "        'brightness': brightness_values,\n",
        "        'contrast': contrast_values,\n",
        "        'sharpness': sharpness_values\n",
        "    }\n",
        "\n",
        "# í’ˆì§ˆ ë¶„ì„\n",
        "quality_stats = analyze_image_quality(stats['image_paths'])\n",
        "\n",
        "print(f\"\\nâœ… í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ!\")\n",
        "print(f\"\\nğŸ“Š ì´ë¯¸ì§€ í’ˆì§ˆ í†µê³„:\")\n",
        "print(f\"   í‰ê·  ë°ê¸°: {np.mean(quality_stats['brightness']):.2f} (0-255)\")\n",
        "print(f\"   í‰ê·  ëŒ€ë¹„: {np.mean(quality_stats['contrast']):.2f}\")\n",
        "print(f\"   í‰ê·  ì„ ëª…ë„: {np.mean(quality_stats['sharpness']):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í’ˆì§ˆ ì§€í‘œ ì‹œê°í™”\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# 1. ë°ê¸° ë¶„í¬\n",
        "axes[0].hist(quality_stats['brightness'], bins=50, color='#f39c12', alpha=0.7)\n",
        "axes[0].set_title('ë°ê¸° ë¶„í¬', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xlabel('ë°ê¸° (0-255)')\n",
        "axes[0].set_ylabel('ë¹ˆë„')\n",
        "axes[0].grid(alpha=0.3)\n",
        "axes[0].axvline(np.mean(quality_stats['brightness']), color='red', linestyle='--',\n",
        "                label=f'í‰ê· : {np.mean(quality_stats[\"brightness\"]):.1f}')\n",
        "axes[0].legend()\n",
        "\n",
        "# 2. ëŒ€ë¹„ ë¶„í¬\n",
        "axes[1].hist(quality_stats['contrast'], bins=50, color='#9b59b6', alpha=0.7)\n",
        "axes[1].set_title('ëŒ€ë¹„ ë¶„í¬', fontsize=12, fontweight='bold')\n",
        "axes[1].set_xlabel('ëŒ€ë¹„ (í‘œì¤€í¸ì°¨)')\n",
        "axes[1].set_ylabel('ë¹ˆë„')\n",
        "axes[1].grid(alpha=0.3)\n",
        "axes[1].axvline(np.mean(quality_stats['contrast']), color='red', linestyle='--',\n",
        "                label=f'í‰ê· : {np.mean(quality_stats[\"contrast\"]):.1f}')\n",
        "axes[1].legend()\n",
        "\n",
        "# 3. ì„ ëª…ë„ ë¶„í¬\n",
        "axes[2].hist(quality_stats['sharpness'], bins=50, color='#1abc9c', alpha=0.7)\n",
        "axes[2].set_title('ì„ ëª…ë„ ë¶„í¬', fontsize=12, fontweight='bold')\n",
        "axes[2].set_xlabel('ì„ ëª…ë„ (Laplacian ë¶„ì‚°)')\n",
        "axes[2].set_ylabel('ë¹ˆë„')\n",
        "axes[2].grid(alpha=0.3)\n",
        "axes[2].axvline(np.mean(quality_stats['sharpness']), color='red', linestyle='--',\n",
        "                label=f'í‰ê· : {np.mean(quality_stats[\"sharpness\"]):.1f}')\n",
        "axes[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_samples(image_paths, categories, num_samples=12):\n",
        "    \"\"\"\n",
        "    ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™”\n",
        "    \n",
        "    Args:\n",
        "        image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "        categories: ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸\n",
        "        num_samples: í‘œì‹œí•  ìƒ˜í”Œ ìˆ˜\n",
        "    \"\"\"\n",
        "    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìƒ˜í”Œ ì„ íƒ\n",
        "    real_paths = [path for path, cat in zip(image_paths, categories) if cat == 'real']\n",
        "    fake_paths = [path for path, cat in zip(image_paths, categories) if cat == 'fake']\n",
        "    \n",
        "    # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒ˜í”Œ ì„ íƒ\n",
        "    import random\n",
        "    random.seed(42)\n",
        "    \n",
        "    num_per_category = num_samples // 2\n",
        "    selected_real = random.sample(real_paths, min(num_per_category, len(real_paths)))\n",
        "    selected_fake = random.sample(fake_paths, min(num_per_category, len(fake_paths)))\n",
        "    \n",
        "    # ì‹œê°í™”\n",
        "    fig, axes = plt.subplots(2, num_per_category, figsize=(num_per_category * 2, 4))\n",
        "    \n",
        "    # Real ì´ë¯¸ì§€\n",
        "    for idx, img_path in enumerate(selected_real):\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            axes[0, idx].imshow(img)\n",
        "            axes[0, idx].set_title(f'Real\\\\n{img.size[0]}x{img.size[1]}', fontsize=8)\n",
        "            axes[0, idx].axis('off')\n",
        "        except:\n",
        "            axes[0, idx].axis('off')\n",
        "    \n",
        "    # Fake ì´ë¯¸ì§€\n",
        "    for idx, img_path in enumerate(selected_fake):\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            axes[1, idx].imshow(img)\n",
        "            axes[1, idx].set_title(f'Fake\\\\n{img.size[0]}x{img.size[1]}', fontsize=8)\n",
        "            axes[1, idx].axis('off')\n",
        "        except:\n",
        "            axes[1, idx].axis('off')\n",
        "    \n",
        "    plt.suptitle('ìƒ˜í”Œ ì´ë¯¸ì§€ (Real vs Fake)', fontsize=14, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ìƒ˜í”Œ ì‹œê°í™”\n",
        "if len(stats['image_paths']) > 0:\n",
        "    visualize_samples(stats['image_paths'], stats['categories'], num_samples=12)\n",
        "else:\n",
        "    print(\"âš ï¸  ì‹œê°í™”í•  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ë°ì´í„°ì…‹ë³„ íŠ¹ì„± ë¹„êµ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„°ì…‹ë³„ í†µê³„ ë¹„êµ\n",
        "if stats['by_dataset']:\n",
        "    dataset_df = pd.DataFrame({\n",
        "        'dataset': list(stats['by_dataset'].keys()),\n",
        "        'count': list(stats['by_dataset'].values())\n",
        "    })\n",
        "    \n",
        "    # ì‹œê°í™”\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "    bars = ax.bar(dataset_df['dataset'], dataset_df['count'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
        "    ax.set_title('ë°ì´í„°ì…‹ë³„ ì´ë¯¸ì§€ ìˆ˜', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('ì´ë¯¸ì§€ ìˆ˜', fontsize=12)\n",
        "    ax.set_xlabel('ë°ì´í„°ì…‹', fontsize=12)\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # ê°’ í‘œì‹œ\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{int(height):,}', ha='center', va='bottom', fontsize=10)\n",
        "    \n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\\\nğŸ“Š ë°ì´í„°ì…‹ë³„ í†µê³„:\")\n",
        "    print(dataset_df.to_string(index=False))\n",
        "else:\n",
        "    print(\"âš ï¸  ë°ì´í„°ì…‹ë³„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ë¬¸ì œ ì •ì˜: \"ì™œ ì´ ë°ì´í„°ê°€ ì–´ë ¤ìš´ê°€?\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë¬¸ì œ ì •ì˜ ë° ì–´ë ¤ì›€ ë¶„ì„\n",
        "print(\"=\" * 70)\n",
        "print(\"ğŸ” ë¬¸ì œ ì •ì˜: ì™œ ì´ ë°ì´í„°ê°€ ì–´ë ¤ìš´ê°€?\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "difficulties = []\n",
        "\n",
        "# 1. í´ë˜ìŠ¤ ë¶ˆê· í˜•\n",
        "if len(stats['by_category']) >= 2:\n",
        "    counts = list(stats['by_category'].values())\n",
        "    imbalance = max(counts) / min(counts)\n",
        "    if imbalance > 3:\n",
        "        difficulties.append({\n",
        "            'issue': 'í´ë˜ìŠ¤ ë¶ˆê· í˜•',\n",
        "            'severity': 'ë†’ìŒ',\n",
        "            'description': f'í´ë˜ìŠ¤ ë¹„ìœ¨ì´ {imbalance:.1f}:1ë¡œ ë¶ˆê· í˜•í•©ë‹ˆë‹¤.',\n",
        "            'impact': 'ëª¨ë¸ì´ ë‹¤ìˆ˜ í´ë˜ìŠ¤ì— í¸í–¥ë  ìˆ˜ ìˆìŒ',\n",
        "            'solution': 'ë°ì´í„° ì¦ê°•, í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜, ìƒ˜í”Œë§ ì „ëµ í•„ìš”'\n",
        "        })\n",
        "\n",
        "# 2. í•´ìƒë„ ë‹¤ì–‘ì„±\n",
        "if resolution_stats['resolutions']:\n",
        "    width_std = np.std(resolution_stats['widths'])\n",
        "    height_std = np.std(resolution_stats['heights'])\n",
        "    if width_std > 200 or height_std > 200:\n",
        "        difficulties.append({\n",
        "            'issue': 'í•´ìƒë„ ë‹¤ì–‘ì„±',\n",
        "            'severity': 'ì¤‘ê°„',\n",
        "            'description': f'í•´ìƒë„ í‘œì¤€í¸ì°¨ê°€ í½ë‹ˆë‹¤ (ë„ˆë¹„: {width_std:.0f}px, ë†’ì´: {height_std:.0f}px)',\n",
        "            'impact': 'ëª¨ë¸ í•™ìŠµ ì‹œ ì¼ê´€ì„± ìˆëŠ” íŠ¹ì§• ì¶”ì¶œì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ',\n",
        "            'solution': 'ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ë° ì •ê·œí™” í•„ìš”'\n",
        "        })\n",
        "\n",
        "# 3. ì´ë¯¸ì§€ í’ˆì§ˆ\n",
        "if quality_stats['sharpness']:\n",
        "    avg_sharpness = np.mean(quality_stats['sharpness'])\n",
        "    if avg_sharpness < 100:\n",
        "        difficulties.append({\n",
        "            'issue': 'ì´ë¯¸ì§€ ì„ ëª…ë„',\n",
        "            'severity': 'ì¤‘ê°„',\n",
        "            'description': f'í‰ê·  ì„ ëª…ë„ê°€ ë‚®ìŠµë‹ˆë‹¤ ({avg_sharpness:.1f})',\n",
        "            'impact': 'ë…¸ì´ì¦ˆê°€ ë§ê±°ë‚˜ íë¦° ì´ë¯¸ì§€ë¡œ ì¸í•´ íŠ¹ì§• ì¶”ì¶œì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ',\n",
        "            'solution': 'ì „ì²˜ë¦¬(ë…¸ì´ì¦ˆ ì œê±°, ìƒ¤í”„ë‹) ë˜ëŠ” ë°ì´í„° í•„í„°ë§ ê³ ë ¤'\n",
        "        })\n",
        "\n",
        "# 4. ë°ì´í„°ì…‹ ë‹¤ì–‘ì„±\n",
        "if len(stats['by_dataset']) > 1:\n",
        "    dataset_counts = list(stats['by_dataset'].values())\n",
        "    dataset_imbalance = max(dataset_counts) / min(dataset_counts)\n",
        "    if dataset_imbalance > 10:\n",
        "        difficulties.append({\n",
        "            'issue': 'ë°ì´í„°ì…‹ ë¶ˆê· í˜•',\n",
        "            'severity': 'ì¤‘ê°„',\n",
        "            'description': f'ë°ì´í„°ì…‹ ê°„ í¬ê¸° ì°¨ì´ê°€ í½ë‹ˆë‹¤ ({dataset_imbalance:.1f}:1)',\n",
        "            'impact': 'íŠ¹ì • ë°ì´í„°ì…‹ì— ê³¼ì í•©ë  ìˆ˜ ìˆìŒ',\n",
        "            'solution': 'ë°ì´í„°ì…‹ ê°„ ê· í˜• ì¡°ì • ë˜ëŠ” êµì°¨ ê²€ì¦ ì „ëµ í•„ìš”'\n",
        "        })\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "if difficulties:\n",
        "    for i, diff in enumerate(difficulties, 1):\n",
        "        print(f\"\\\\n{i}. {diff['issue']} [{diff['severity']}]\")\n",
        "        print(f\"   ì„¤ëª…: {diff['description']}\")\n",
        "        print(f\"   ì˜í–¥: {diff['impact']}\")\n",
        "        print(f\"   í•´ê²°ì±…: {diff['solution']}\")\n",
        "else:\n",
        "    print(\"\\\\nâœ… íŠ¹ë³„í•œ ì–´ë ¤ì›€ì„ ë°œê²¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 70)\n",
        "print(\"ğŸ“ ì¢…í•© ë¶„ì„ ìš”ì•½\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"ì´ ì´ë¯¸ì§€ ìˆ˜: {stats['total_images']:,}ê°œ\")\n",
        "print(f\"í´ë˜ìŠ¤ ìˆ˜: {len(stats['by_category'])}ê°œ\")\n",
        "if stats['by_category']:\n",
        "    for cat, count in stats['by_category'].items():\n",
        "        print(f\"  - {cat}: {count:,}ê°œ\")\n",
        "print(f\"\\\\nì£¼ìš” ë„ì „ ê³¼ì œ: {len(difficulties)}ê°œ ë°œê²¬\")\n",
        "print(\"\\\\nê¶Œì¥ ì‚¬í•­:\")\n",
        "print(\"1. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì •ê·œí™”\")\n",
        "print(\"2. í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°ì„ ìœ„í•œ ë°ì´í„° ì¦ê°•\")\n",
        "print(\"3. ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì‹¤í—˜ (CNN, ViT)\")\n",
        "print(\"4. êµì°¨ ê²€ì¦ì„ í†µí•œ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
