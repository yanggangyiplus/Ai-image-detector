{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ViT ëª¨ë¸ Fine-tuning ë° í‰ê°€\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” Vision Transformer ëª¨ë¸ì„ Fine-tuningí•˜ê³  ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ëª©í‘œ\n",
        "- ViT ëª¨ë¸ Fine-tuning\n",
        "- ì„±ëŠ¥ ì§€í‘œ ê¸°ë¡ (Accuracy, F1-score, Confusion Matrix)\n",
        "- Loss Curve ì‹œê°í™”\n",
        "- ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "import sys\n",
        "sys.path.insert(0, '../src')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import\n",
        "from models.model_utils import create_vit_model, print_model_info\n",
        "from data.dataset import ImageDataset\n",
        "from data.preprocess import get_train_transforms, get_val_transforms\n",
        "from training.loss_functions import get_loss_function\n",
        "from training.optimizer import create_optimizer, create_scheduler\n",
        "from training.train import train_model, EarlyStopping\n",
        "from training.metrics import calculate_all_metrics, print_metrics, plot_confusion_matrix\n",
        "from training.evaluator import evaluate_model\n",
        "from utils.seed import set_seed\n",
        "\n",
        "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì‹œë“œ ê³ ì •\n",
        "set_seed(42)\n",
        "\n",
        "# ê²½ë¡œ ì„¤ì •\n",
        "DATA_DIR = Path(\"../data\")\n",
        "TRAIN_DIR = DATA_DIR / \"train\"\n",
        "VAL_DIR = DATA_DIR / \"val\"\n",
        "TEST_DIR = DATA_DIR / \"test\"\n",
        "CHECKPOINT_DIR = Path(\"../experiments/checkpoints\")\n",
        "LOG_DIR = Path(\"../experiments/logs\")\n",
        "RESULTS_DIR = Path(\"../experiments/results\")\n",
        "\n",
        "# ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ì„¤ì •\n",
        "CONFIG = {\n",
        "    'model_name': 'vit_base',  # 'vit_base', 'vit_for_classification'\n",
        "    'num_classes': 2,\n",
        "    'batch_size': 16,  # ViTëŠ” ë©”ëª¨ë¦¬ë¥¼ ë” ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ì‘ì€ ë°°ì¹˜ í¬ê¸°\n",
        "    'num_epochs': 30,\n",
        "    'learning_rate': 1e-5,  # Fine-tuningì„ ìœ„í•´ ì‘ì€ í•™ìŠµë¥ \n",
        "    'weight_decay': 1e-4,\n",
        "    'image_size': 224,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'class_names': ['real', 'fake'],\n",
        "    'class_map': {'real': '0', 'fake': '1'},\n",
        "    'freeze_backbone': False,  # Trueë¡œ ì„¤ì •í•˜ë©´ ì¼ë¶€ ë ˆì´ì–´ ê³ ì •\n",
        "    'freeze_layers': None  # ê³ ì •í•  ë ˆì´ì–´ ìˆ˜ (Noneì´ë©´ ìë™)\n",
        "}\n",
        "\n",
        "print(f\"ë””ë°”ì´ìŠ¤: {CONFIG['device']}\")\n",
        "print(f\"ëª¨ë¸: {CONFIG['model_name']}\")\n",
        "print(f\"ë°°ì¹˜ í¬ê¸°: {CONFIG['batch_size']}\")\n",
        "print(f\"ì—í¬í¬ ìˆ˜: {CONFIG['num_epochs']}\")\n",
        "print(f\"Fine-tuning ëª¨ë“œ: freeze_backbone={CONFIG['freeze_backbone']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n",
        "train_transform = get_train_transforms(CONFIG['image_size'])\n",
        "val_transform = get_val_transforms(CONFIG['image_size'])\n",
        "test_transform = get_val_transforms(CONFIG['image_size'])\n",
        "\n",
        "# ë°ì´í„°ì…‹ ìƒì„±\n",
        "train_dataset = ImageDataset(TRAIN_DIR, CONFIG['class_map'], transform=train_transform)\n",
        "val_dataset = ImageDataset(VAL_DIR, CONFIG['class_map'], transform=val_transform)\n",
        "test_dataset = ImageDataset(TEST_DIR, CONFIG['class_map'], transform=test_transform)\n",
        "\n",
        "# ë°ì´í„°ë¡œë” ìƒì„±\n",
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=4)\n",
        "\n",
        "print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_dataset)}ê°œ\")\n",
        "print(f\"ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_dataset)}ê°œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ëª¨ë¸ ìƒì„±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ViT ëª¨ë¸ ìƒì„± (Fine-tuning êµ¬ì¡°)\n",
        "model = create_vit_model(\n",
        "    model_name=CONFIG['model_name'],\n",
        "    num_classes=CONFIG['num_classes'],\n",
        "    pretrained=True,\n",
        "    freeze_backbone=CONFIG['freeze_backbone'],\n",
        "    freeze_layers=CONFIG['freeze_layers']\n",
        ")\n",
        "\n",
        "model = model.to(CONFIG['device'])\n",
        "print_model_info(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loss, Optimizer, Scheduler ì„¤ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss í•¨ìˆ˜\n",
        "criterion = get_loss_function('cross_entropy')\n",
        "\n",
        "# Optimizer\n",
        "optimizer = create_optimizer(\n",
        "    model,\n",
        "    'adamw',\n",
        "    learning_rate=CONFIG['learning_rate'],\n",
        "    weight_decay=CONFIG['weight_decay']\n",
        ")\n",
        "\n",
        "# Scheduler\n",
        "scheduler = create_scheduler(\n",
        "    optimizer,\n",
        "    'reduce_lr_on_plateau',  # ViTëŠ” ReduceLROnPlateauê°€ ë” íš¨ê³¼ì \n",
        "    patience=5,\n",
        "    factor=0.5\n",
        ")\n",
        "\n",
        "# Early Stopping\n",
        "early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ëª¨ë¸ Fine-tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tuning ì‹¤í–‰\n",
        "model_name = f\"ViT_{CONFIG['model_name']}\"\n",
        "history = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=CONFIG['num_epochs'],\n",
        "    device=CONFIG['device'],\n",
        "    class_names=CONFIG['class_names'],\n",
        "    save_dir=CHECKPOINT_DIR,\n",
        "    log_dir=LOG_DIR,\n",
        "    model_name=model_name,\n",
        "    early_stopping=early_stopping,\n",
        "    scheduler_name='reduce_lr_on_plateau'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loss Curve ì‹œê°í™”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss Curve ê·¸ë¦¬ê¸°\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss Curve\n",
        "axes[0].plot(history['train_loss'], label='Train Loss', color='blue')\n",
        "axes[0].plot(history['val_loss'], label='Val Loss', color='red')\n",
        "axes[0].set_title('Loss Curve', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy Curve\n",
        "axes[1].plot(history['train_accuracy'], label='Train Accuracy', color='blue')\n",
        "axes[1].plot(history['val_accuracy'], label='Val Accuracy', color='red')\n",
        "axes[1].set_title('Accuracy Curve', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(RESULTS_DIR / f'{model_name}_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"âœ… ê·¸ë˜í”„ ì €ì¥: {RESULTS_DIR / f'{model_name}_curves.png'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Best ëª¨ë¸ ë¡œë“œ\n",
        "best_model_path = CHECKPOINT_DIR / f'{model_name}_best.pth'\n",
        "checkpoint = torch.load(best_model_path, map_location=CONFIG['device'])\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(f\"âœ… Best ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Epoch {checkpoint['epoch']})\")\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€\n",
        "test_results = evaluate_model(\n",
        "    model,\n",
        "    test_loader,\n",
        "    CONFIG['device'],\n",
        "    class_names=CONFIG['class_names']\n",
        ")\n",
        "\n",
        "# ë©”íŠ¸ë¦­ ì¶œë ¥\n",
        "print_metrics(test_results['metrics'], class_names=CONFIG['class_names'])\n",
        "\n",
        "# ê²°ê³¼ ì €ì¥\n",
        "test_metrics = {\n",
        "    'accuracy': test_results['metrics']['accuracy'],\n",
        "    'precision': test_results['metrics']['precision'],\n",
        "    'recall': test_results['metrics']['recall'],\n",
        "    'f1': test_results['metrics']['f1'],\n",
        "    'confusion_matrix': test_results['metrics']['confusion_matrix'].tolist()\n",
        "}\n",
        "\n",
        "with open(RESULTS_DIR / f'{model_name}_test_metrics.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(test_metrics, f, indent=2, ensure_ascii=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix ì‹œê°í™”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix ì‹œê°í™”\n",
        "cm = test_results['metrics']['confusion_matrix']\n",
        "plot_confusion_matrix(\n",
        "    cm,\n",
        "    CONFIG['class_names'],\n",
        "    save_path=RESULTS_DIR / f'{model_name}_confusion_matrix.png'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ì°¾ê¸°\n",
        "model.eval()\n",
        "misclassified_samples = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc=\"ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ì°¾ëŠ” ì¤‘\"):\n",
        "        images = images.to(CONFIG['device'])\n",
        "        labels = labels.to(CONFIG['device'])\n",
        "        \n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        # ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ì°¾ê¸°\n",
        "        incorrect = (predicted != labels).cpu().numpy()\n",
        "        for i in range(len(images)):\n",
        "            if incorrect[i]:\n",
        "                misclassified_samples.append({\n",
        "                    'image': images[i].cpu(),\n",
        "                    'true_label': labels[i].item(),\n",
        "                    'pred_label': predicted[i].item(),\n",
        "                    'confidence': torch.softmax(outputs[i], dim=0)[predicted[i]].item()\n",
        "                })\n",
        "\n",
        "print(f\"ì´ ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ìˆ˜: {len(misclassified_samples)}ê°œ\")\n",
        "\n",
        "# ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ì‹œê°í™” (ìµœëŒ€ 16ê°œ)\n",
        "num_samples = min(16, len(misclassified_samples))\n",
        "if num_samples > 0:\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx in range(num_samples):\n",
        "        sample = misclassified_samples[idx]\n",
        "        img = sample['image']\n",
        "        true_label = CONFIG['class_names'][sample['true_label']]\n",
        "        pred_label = CONFIG['class_names'][sample['pred_label']]\n",
        "        conf = sample['confidence']\n",
        "        \n",
        "        # ì´ë¯¸ì§€ ì •ê·œí™” í•´ì œ ë° í‘œì‹œ\n",
        "        img_denorm = img.permute(1, 2, 0)\n",
        "        img_denorm = torch.clamp(img_denorm, 0, 1)\n",
        "        \n",
        "        axes[idx].imshow(img_denorm.numpy())\n",
        "        axes[idx].set_title(f'True: {true_label}\\\\nPred: {pred_label} ({conf:.2f})',\n",
        "                           fontsize=10, color='red' if true_label != pred_label else 'green')\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    # ë¹ˆ subplot ìˆ¨ê¸°ê¸°\n",
        "    for idx in range(num_samples, len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.suptitle(f'Misclassified Samples ({num_samples}ê°œ)', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(RESULTS_DIR / f'{model_name}_misclassified.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"âœ… ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ì €ì¥: {RESULTS_DIR / f'{model_name}_misclassified.png'}\")\n",
        "else:\n",
        "    print(\"ì˜¤ë¶„ë¥˜ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ê²°ê³¼ ìš”ì•½\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"ğŸ“Š ViT ëª¨ë¸ Fine-tuning ê²°ê³¼ ìš”ì•½\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"ëª¨ë¸: {CONFIG['model_name']}\")\n",
        "print(f\"Best Epoch: {history['best_epoch']}\")\n",
        "print(f\"Best Val Loss: {history['best_val_loss']:.4f}\")\n",
        "print(f\"Best Val Accuracy: {history['best_val_accuracy']:.4f}\")\n",
        "print(f\"\\\\ní…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì„±ëŠ¥:\")\n",
        "print(f\"  Accuracy:  {test_metrics['accuracy']:.4f} ({test_metrics['accuracy']*100:.2f}%)\")\n",
        "print(f\"  Precision: {test_metrics['precision']:.4f}\")\n",
        "print(f\"  Recall:    {test_metrics['recall']:.4f}\")\n",
        "print(f\"  F1 Score:  {test_metrics['f1']:.4f}\")\n",
        "print(f\"\\\\nì €ì¥ëœ íŒŒì¼:\")\n",
        "print(f\"  - ì²´í¬í¬ì¸íŠ¸: {CHECKPOINT_DIR / f'{model_name}_best.pth'}\")\n",
        "print(f\"  - Loss Curve: {RESULTS_DIR / f'{model_name}_curves.png'}\")\n",
        "print(f\"  - Confusion Matrix: {RESULTS_DIR / f'{model_name}_confusion_matrix.png'}\")\n",
        "print(f\"  - Misclassified: {RESULTS_DIR / f'{model_name}_misclassified.png'}\")\n",
        "print(f\"  - ë©”íŠ¸ë¦­: {RESULTS_DIR / f'{model_name}_test_metrics.json'}\")\n",
        "print(\"=\" * 70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
